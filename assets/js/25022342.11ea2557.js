"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[433],{7604(n,e,r){r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>s,metadata:()=>a,toc:()=>_});const a=JSON.parse('{"id":"module-3/nav2-path-planning","title":"Nav2 Path Planning","description":"Comprehensive guide to path planning using Nav2 for humanoid robotics applications","source":"@site/docs/module-3/nav2-path-planning.md","sourceDirName":"module-3","slug":"/module-3/nav2-path-planning","permalink":"/physical-ai/docs/module-3/nav2-path-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-textbook/book-ai/tree/main/docs/module-3/nav2-path-planning.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"nav2-path-planning","title":"Nav2 Path Planning","sidebar_position":6,"description":"Comprehensive guide to path planning using Nav2 for humanoid robotics applications","keywords":["nav2","path planning","navigation","robotics","pathfinding","humanoid navigation","navigation2"]},"sidebar":"textbook","previous":{"title":"Isaac ROS VSLAM","permalink":"/physical-ai/docs/module-3/isaac-vslam"},"next":{"title":"Sim-to-Real Transfer","permalink":"/physical-ai/docs/module-3/sim-to-real"}}');var t=r(4848),o=r(8453);const s={id:"nav2-path-planning",title:"Nav2 Path Planning",sidebar_position:6,description:"Comprehensive guide to path planning using Nav2 for humanoid robotics applications",keywords:["nav2","path planning","navigation","robotics","pathfinding","humanoid navigation","navigation2"]},i="Nav2 Path Planning: Bipedal Navigation Systems",l={},_=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Nav2",id:"introduction-to-nav2",level:2},{value:"What is Nav2?",id:"what-is-nav2",level:3},{value:"Key Features of Nav2",id:"key-features-of-nav2",level:3},{value:"Nav2 vs Legacy Navigation Stack",id:"nav2-vs-legacy-navigation-stack",level:3},{value:"Nav2 Architecture",id:"nav2-architecture",level:2},{value:"Core Components",id:"core-components",level:3},{value:"Behavior Tree Integration",id:"behavior-tree-integration",level:3},{value:"Nav2 Installation and Setup",id:"nav2-installation-and-setup",level:2},{value:"Installing Nav2",id:"installing-nav2",level:3},{value:"Basic Nav2 Launch",id:"basic-nav2-launch",level:3},{value:"Configuration Files",id:"configuration-files",level:2},{value:"Nav2 Parameters Configuration",id:"nav2-parameters-configuration",level:3},{value:"Path Planning Algorithms",id:"path-planning-algorithms",level:2},{value:"Global Path Planning",id:"global-path-planning",level:3},{value:"Local Path Planning and Trajectory Generation",id:"local-path-planning-and-trajectory-generation",level:3},{value:"Humanoid-Specific Navigation Considerations",id:"humanoid-specific-navigation-considerations",level:2},{value:"Bipedal Locomotion Planning",id:"bipedal-locomotion-planning",level:3},{value:"Integration with Perception Systems",id:"integration-with-perception-systems",level:2},{value:"Sensor Integration for Navigation",id:"sensor-integration-for-navigation",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Navigation Performance Tuning",id:"navigation-performance-tuning",level:3},{value:"Troubleshooting and Best Practices",id:"troubleshooting-and-best-practices",level:2},{value:"Common Navigation Issues and Solutions",id:"common-navigation-issues-and-solutions",level:3},{value:"Learning Objectives Review",id:"learning-objectives-review",level:2},{value:"Practical Exercise",id:"practical-exercise",level:2},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Further Reading",id:"further-reading",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"nav2-path-planning-bipedal-navigation-systems",children:"Nav2 Path Planning: Bipedal Navigation Systems"})}),"\n",(0,t.jsx)(e.p,{children:"Navigation is a fundamental capability for humanoid robots, enabling them to move safely and efficiently through environments. This chapter covers the Nav2 framework, which provides a comprehensive navigation system for robots, with specific focus on humanoid applications."}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand Nav2 architecture and components"}),"\n",(0,t.jsx)(e.li,{children:"Configure Nav2 for humanoid robotics applications"}),"\n",(0,t.jsx)(e.li,{children:"Implement path planning algorithms for bipedal locomotion"}),"\n",(0,t.jsx)(e.li,{children:"Integrate perception systems with navigation"}),"\n",(0,t.jsx)(e.li,{children:"Optimize navigation for dynamic environments"}),"\n",(0,t.jsx)(e.li,{children:"Troubleshoot common navigation issues"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-nav2",children:"Introduction to Nav2"}),"\n",(0,t.jsx)(e.h3,{id:"what-is-nav2",children:"What is Nav2?"}),"\n",(0,t.jsx)(e.p,{children:"Nav2 (Navigation 2) is the next-generation navigation framework for ROS 2, designed to provide safe and reliable path planning and navigation for robots. It builds upon the lessons learned from ROS 1's navigation stack with significant improvements."}),"\n",(0,t.jsx)(e.h3,{id:"key-features-of-nav2",children:"Key Features of Nav2"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Modular Architecture"}),": Pluggable components for flexibility"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Behavior Trees"}),": Declarative behavior specification"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Advanced Planning"}),": Sophisticated path planning algorithms"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Recovery Behaviors"}),": Robust recovery from navigation failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simulation Integration"}),": Seamless simulation-to-real transfer"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Performance"}),": Optimized for real-time applications"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"nav2-vs-legacy-navigation-stack",children:"Nav2 vs Legacy Navigation Stack"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Aspect"}),(0,t.jsx)(e.th,{children:"Nav2"}),(0,t.jsx)(e.th,{children:"Legacy Navigation"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Architecture"}),(0,t.jsx)(e.td,{children:"Component-based with BT"}),(0,t.jsx)(e.td,{children:"Monolithic nodes"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Behavior Logic"}),(0,t.jsx)(e.td,{children:"Behavior Trees"}),(0,t.jsx)(e.td,{children:"Hardcoded state machines"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Flexibility"}),(0,t.jsx)(e.td,{children:"Highly configurable"}),(0,t.jsx)(e.td,{children:"Limited customization"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Recovery"}),(0,t.jsx)(e.td,{children:"Sophisticated recovery"}),(0,t.jsx)(e.td,{children:"Basic recovery"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Performance"}),(0,t.jsx)(e.td,{children:"Optimized for ROS 2"}),(0,t.jsx)(e.td,{children:"Designed for ROS 1"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Simulation"}),(0,t.jsx)(e.td,{children:"Integrated simulation"}),(0,t.jsx)(e.td,{children:"Separate tools"})]})]})]}),"\n",(0,t.jsx)(e.h2,{id:"nav2-architecture",children:"Nav2 Architecture"}),"\n",(0,t.jsx)(e.h3,{id:"core-components",children:"Core Components"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                        Nav2 Architecture                        \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502  \u2502   Planner       \u2502  \u2502   Controller    \u2502  \u2502   Recovery      \u2502  \u2502\r\n\u2502  \u2502   Server        \u2502  \u2502   Server        \u2502  \u2502   Server        \u2502  \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502         \u2502                       \u2502                       \u2502       \u2502\r\n\u2502         \u25bc                       \u25bc                       \u25bc       \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502  \u2502   Global        \u2502  \u2502   Local         \u2502  \u2502   Recovery      \u2502  \u2502\r\n\u2502  \u2502   Planner       \u2502  \u2502   Planner       \u2502  \u2502   Behaviors     \u2502  \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502         \u2502                       \u2502                       \u2502       \u2502\r\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\r\n\u2502                                 \u25bc                               \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\r\n\u2502  \u2502                Behavior Tree Executor                       \u2502 \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\r\n\u2502                                 \u2502                               \u2502\r\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\r\n\u2502         \u25bc                       \u25bc                       \u25bc       \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502  \u2502   Costmap       \u2502  \u2502   Transform     \u2502  \u2502   Sensors       \u2502  \u2502\r\n\u2502  \u2502   Server        \u2502  \u2502   Server        \u2502  \u2502   Server        \u2502  \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(e.h3,{id:"behavior-tree-integration",children:"Behavior Tree Integration"}),"\n",(0,t.jsx)(e.p,{children:"Nav2 uses Behavior Trees (BT) to orchestrate navigation tasks:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<root main_tree_to_execute="MainTree">\r\n  <BehaviorTree ID="MainTree">\r\n    <PipelineSequence name="NavigateWithReplanning">\r\n      <RateController hz="1.0">\r\n        <ComputePathToPose goal="{goal}" path="{path}" planner_id="GridBased"/>\r\n      </RateController>\r\n      <FollowPath path="{path}" controller_id="FollowPath"/>\r\n    </PipelineSequence>\r\n  </BehaviorTree>\r\n</root>\n'})}),"\n",(0,t.jsx)(e.h2,{id:"nav2-installation-and-setup",children:"Nav2 Installation and Setup"}),"\n",(0,t.jsx)(e.h3,{id:"installing-nav2",children:"Installing Nav2"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Install Nav2 packages\r\nsudo apt update\r\nsudo apt install ros-humble-navigation2 ros-humble-nav2-bringup\r\n\r\n# Install additional tools\r\nsudo apt install ros-humble-nav2-rviz-plugins\r\nsudo apt install ros-humble-nav2-system-tests\r\nsudo apt install ros-humble-nav2-map-server\r\nsudo apt install ros-humble-nav2-lifecycle-manager\r\nsudo apt install ros-humble-nav2-planners\r\nsudo apt install ros-humble-nav2-controller\r\nsudo apt install ros-humble-nav2-behaviors\n"})}),"\n",(0,t.jsx)(e.h3,{id:"basic-nav2-launch",children:"Basic Nav2 Launch"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# launch/basic_nav2_launch.py\r\nfrom launch import LaunchDescription\r\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\r\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom launch_ros.actions import Node\r\nfrom launch_ros.substitutions import FindPackageShare\r\n\r\ndef generate_launch_description():\r\n    # Launch arguments\r\n    use_sim_time = LaunchConfiguration('use_sim_time', default='false')\r\n    map_yaml_file = LaunchConfiguration('map', default='')\r\n    params_file = LaunchConfiguration('params_file')\r\n    autostart = LaunchConfiguration('autostart', default='true')\r\n    rviz_config_file = LaunchConfiguration('rviz_config', default='nav2_default_view.rviz')\r\n\r\n    # Package locations\r\n    pkg_nav2_bringup = FindPackageShare('nav2_bringup')\r\n    pkg_nav2_bt_navigator = FindPackageShare('nav2_bt_navigator')\r\n\r\n    # Launch files\r\n    localization_launch = IncludeLaunchDescription(\r\n        PythonLaunchDescriptionSource([\r\n            PathJoinSubstitution([\r\n                pkg_nav2_bringup,\r\n                'launch',\r\n                'localization.launch.py'\r\n            ])\r\n        ]),\r\n        launch_arguments={\r\n            'map': map_yaml_file,\r\n            'use_sim_time': use_sim_time,\r\n            'params_file': params_file\r\n        }.items()\r\n    )\r\n\r\n    navigation_launch = IncludeLaunchDescription(\r\n        PythonLaunchDescriptionSource([\r\n            PathJoinSubstitution([\r\n                pkg_nav2_bringup,\r\n                'launch',\r\n                'navigation.launch.py'\r\n            ])\r\n        ]),\r\n        launch_arguments={\r\n            'use_sim_time': use_sim_time,\r\n            'params_file': params_file,\r\n            'autostart': autostart\r\n        }.items()\r\n    )\r\n\r\n    # RViz node\r\n    rviz_node = Node(\r\n        package='rviz2',\r\n        executable='rviz2',\r\n        name='rviz2',\r\n        arguments=['-d', PathJoinSubstitution([pkg_nav2_bringup, 'rviz', rviz_config_file])],\r\n        parameters=[{'use_sim_time': use_sim_time}],\r\n        output='screen'\r\n    )\r\n\r\n    return LaunchDescription([\r\n        DeclareLaunchArgument(\r\n            'map',\r\n            default_value='',\r\n            description='Full path to map file to load'\r\n        ),\r\n        DeclareLaunchArgument(\r\n            'params_file',\r\n            default_value=PathJoinSubstitution([\r\n                FindPackageShare('my_robot_navigation'),\r\n                'config',\r\n                'nav2_params.yaml'\r\n            ]),\r\n            description='Full path to the ROS2 parameters file to use for all launched nodes'\r\n        ),\r\n        DeclareLaunchArgument(\r\n            'use_sim_time',\r\n            default_value='false',\r\n            description='Use simulation (Gazebo) clock if true'\r\n        ),\r\n        DeclareLaunchArgument(\r\n            'autostart',\r\n            default_value='true',\r\n            description='Automatically startup the nav2 stack'\r\n        ),\r\n        DeclareLaunchArgument(\r\n            'rviz_config',\r\n            default_value='nav2_default_view.rviz',\r\n            description='Full path to the RViz config file to use'\r\n        ),\r\n        localization_launch,\r\n        navigation_launch,\r\n        rviz_node\r\n    ])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"configuration-files",children:"Configuration Files"}),"\n",(0,t.jsx)(e.h3,{id:"nav2-parameters-configuration",children:"Nav2 Parameters Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# config/nav2_params.yaml\r\namcl:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    alpha1: 0.2\r\n    alpha2: 0.2\r\n    alpha3: 0.2\r\n    alpha4: 0.2\r\n    alpha5: 0.2\r\n    base_frame_id: "base_footprint"\r\n    beam_skip_distance: 0.5\r\n    beam_skip_error_threshold: 0.9\r\n    beam_skip_threshold: 0.3\r\n    do_beamskip: false\r\n    global_frame_id: "map"\r\n    lambda_short: 0.1\r\n    likelihood_max_dist: 2.0\r\n    max_beams: 60\r\n    max_particles: 2000\r\n    min_particles: 500\r\n    odom_frame_id: "odom"\r\n    pf_err: 0.05\r\n    pf_z: 0.5\r\n    recovery_alpha_fast: 0.0\r\n    recovery_alpha_slow: 0.0\r\n    resample_interval: 1\r\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\r\n    save_pose_rate: 0.5\r\n    sigma_hit: 0.2\r\n    tf_broadcast: true\r\n    transform_tolerance: 1.0\r\n    update_min_a: 0.2\r\n    update_min_d: 0.25\r\n    z_hit: 0.5\r\n    z_max: 0.05\r\n    z_rand: 0.5\r\n    z_short: 0.05\r\n    scan_topic: scan\r\n\r\namcl_map_client:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n\r\namcl_rclcpp_node:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n\r\nbt_navigator:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    global_frame: map\r\n    robot_base_frame: base_link\r\n    odom_topic: /odom\r\n    bt_loop_duration: 10\r\n    default_server_timeout: 20\r\n    enable_groot_monitoring: True\r\n    enable_groot_recording: False\r\n    groot_recording_options: {}\r\n    default_nav_through_poses_bt_xml: /opt/ros/humble/share/nav2_bt_navigator/behavior_trees/navigate_w_replanning_and_recovery.xml\r\n    default_navigate_to_pose_bt_xml: /opt/ros/humble/share/nav2_bt_navigator/behavior_trees/navigate_w_replanning_and_recovery.xml\r\n    plugin_lib_names:\r\n    - nav2_compute_path_to_pose_action_bt_node\r\n    - nav2_compute_path_through_poses_action_bt_node\r\n    - nav2_smooth_path_action_bt_node\r\n    - nav2_follow_path_action_bt_node\r\n    - nav2_spin_action_bt_node\r\n    - nav2_wait_action_bt_node\r\n    - nav2_back_up_action_bt_node\r\n    - nav2_drive_on_heading_bt_node\r\n    - nav2_clear_costmap_service_bt_node\r\n    - nav2_is_stuck_condition_bt_node\r\n    - nav2_goal_reached_condition_bt_node\r\n    - nav2_goal_updated_condition_bt_node\r\n    - nav2_globally_cleared_condition_bt_node\r\n    - nav2_locally_cleared_condition_bt_node\r\n    - nav2_map_accessed_condition_bt_node\r\n    - nav2_initial_pose_received_condition_bt_node\r\n    - nav2_reinitialize_global_localization_service_bt_node\r\n    - nav2_rate_controller_bt_node\r\n    - nav2_distance_controller_bt_node\r\n    - nav2_speed_controller_bt_node\r\n    - nav2_truncate_path_action_bt_node\r\n    - nav2_truncate_path_local_action_bt_node\r\n    - nav2_goal_updater_node_bt_node\r\n    - nav2_recovery_node_bt_node\r\n    - nav2_pipeline_sequence_bt_node\r\n    - nav2_round_robin_node_bt_node\r\n    - nav2_transform_available_condition_bt_node\r\n    - nav2_time_expired_condition_bt_node\r\n    - nav2_path_expiring_timer_condition\r\n    - nav2_distance_traveled_condition_bt_node\r\n    - nav2_single_trigger_bt_node\r\n    - nav2_is_battery_low_condition_bt_node\r\n    - nav2_navigate_through_poses_action_bt_node\r\n    - nav2_navigate_to_pose_action_bt_node\r\n    - nav2_remove_passed_goals_action_bt_node\r\n    - nav2_planner_selector_bt_node\r\n    - nav2_controller_selector_bt_node\r\n    - nav2_goal_checker_selector_bt_node\r\n    - nav2_controller_cancel_bt_node\r\n    - nav2_path_longer_on_approach_bt_node\r\n    - nav2_wait_cancel_bt_node\r\n    - nav2_spin_cancel_bt_node\r\n    - nav2_back_up_cancel_bt_node\r\n    - nav2_drive_on_heading_cancel_bt_node\r\n\r\nbt_navigator_rclcpp_node:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n\r\ncontroller_server:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    controller_frequency: 20.0\r\n    min_x_velocity_threshold: 0.001\r\n    min_y_velocity_threshold: 0.5\r\n    min_theta_velocity_threshold: 0.001\r\n    progress_checker_plugin: "progress_checker"\r\n    goal_checker_plugin: "goal_checker"\r\n    controller_plugins: ["FollowPath"]\r\n\r\n    # Progress checker parameters\r\n    progress_checker:\r\n      plugin: "nav2_controller::SimpleProgressChecker"\r\n      required_movement_radius: 0.5\r\n      movement_time_allowance: 10.0\r\n\r\n    # Goal checker parameters\r\n    goal_checker:\r\n      plugin: "nav2_controller::SimpleGoalChecker"\r\n      xy_goal_tolerance: 0.25\r\n      yaw_goal_tolerance: 0.25\r\n      stateful: True\r\n\r\n    # Controller parameters\r\n    FollowPath:\r\n      plugin: "nav2_rotation_shim_controller::RotationShimController"\r\n      # Base local planner parameters\r\n      approximate_linear_controller: "dwb_core::DWBLocalPlanner"\r\n      stopping_feeback: "stopping"\r\n      rotating_feeback: "rotating_cmd"\r\n      moving_feeback: "moving_cmd"\r\n      approximate_angular_controller: "dwb_core::DWBLocalPlanner"\r\n      exact_angular_controller: "nav2_regulated_pure_pursuit_controller::RegulatedPurePursuitController"\r\n\r\ndwb_core:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    debug_trajectory_details: False\r\n    min_vel_x: 0.0\r\n    min_vel_y: 0.0\r\n    max_vel_x: 0.5\r\n    max_vel_y: 0.0\r\n    max_vel_theta: 1.0\r\n    min_speed_xy: 0.0\r\n    max_speed_xy: 0.5\r\n    min_speed_theta: 0.0\r\n    acc_lim_x: 2.5\r\n    acc_lim_y: 0.0\r\n    acc_lim_theta: 3.2\r\n    decel_lim_x: -2.5\r\n    decel_lim_y: 0.0\r\n    decel_lim_theta: -3.2\r\n    vx_samples: 20\r\n    vy_samples: 5\r\n    vtheta_samples: 20\r\n    sim_time: 1.7\r\n    linear_granularity: 0.05\r\n    angular_granularity: 0.025\r\n    transform_tolerance: 0.2\r\n    xy_goal_tolerance: 0.25\r\n    trans_stopped_velocity: 0.25\r\n    short_circuit_trajectory_evaluation: True\r\n    stateful: True\r\n    critics: ["RotateToGoal", "Oscillation", "BaseObstacle", "GoalAlign", "PathAlign", "PathDist", "GoalDist"]\r\n    BaseObstacle.scale: 0.02\r\n    PathAlign.scale: 32.0\r\n    PathAlign.forward_point_distance: 0.1\r\n    GoalAlign.scale: 24.0\r\n    GoalAlign.forward_point_distance: 0.1\r\n    PathDist.scale: 32.0\r\n    GoalDist.scale: 24.0\r\n    RotateToGoal.scale: 32.0\r\n    RotateToGoal.slowing_factor: 5.0\r\n    RotateToGoal.lookahead_time: -1.0\r\n\r\nlocal_costmap:\r\n  local_costmap:\r\n    ros__parameters:\r\n      update_frequency: 5.0\r\n      publish_frequency: 2.0\r\n      global_frame: odom\r\n      robot_base_frame: base_link\r\n      use_sim_time: False\r\n      rolling_window: true\r\n      width: 3\r\n      height: 3\r\n      resolution: 0.05\r\n      robot_radius: 0.22\r\n      plugins: ["voxel_layer", "inflation_layer"]\r\n      inflation_layer:\r\n        plugin: "nav2_costmap_2d::InflationLayer"\r\n        cost_scaling_factor: 3.0\r\n        inflation_radius: 0.55\r\n      voxel_layer:\r\n        plugin: "nav2_costmap_2d::VoxelLayer"\r\n        enabled: True\r\n        publish_voxel_map: False\r\n        origin_z: 0.0\r\n        z_resolution: 0.2\r\n        z_voxels: 10\r\n        max_obstacle_height: 2.0\r\n        mark_threshold: 0\r\n        observation_sources: scan\r\n        scan:\r\n          topic: /scan\r\n          max_obstacle_height: 2.0\r\n          clearing: True\r\n          marking: True\r\n          data_type: "LaserScan"\r\n          raytrace_max_range: 3.0\r\n          raytrace_min_range: 0.0\r\n          obstacle_max_range: 2.5\r\n          obstacle_min_range: 0.0\r\n      static_layer:\r\n        map_subscribe_transient_local: True\r\n      always_send_full_costmap: True\r\n  local_costmap_client:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n  local_costmap_rclcpp_node:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n\r\nglobal_costmap:\r\n  global_costmap:\r\n    ros__parameters:\r\n      update_frequency: 1.0\r\n      publish_frequency: 1.0\r\n      global_frame: map\r\n      robot_base_frame: base_link\r\n      use_sim_time: False\r\n      robot_radius: 0.22\r\n      resolution: 0.05\r\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\r\n      obstacle_layer:\r\n        plugin: "nav2_costmap_2d::ObstacleLayer"\r\n        enabled: True\r\n        observation_sources: scan\r\n        scan:\r\n          topic: /scan\r\n          max_obstacle_height: 2.0\r\n          clearing: True\r\n          marking: True\r\n          data_type: "LaserScan"\r\n          raytrace_max_range: 3.0\r\n          raytrace_min_range: 0.0\r\n          obstacle_max_range: 2.5\r\n          obstacle_min_range: 0.0\r\n      static_layer:\r\n        plugin: "nav2_costmap_2d::StaticLayer"\r\n        map_subscribe_transient_local: True\r\n      inflation_layer:\r\n        plugin: "nav2_costmap_2d::InflationLayer"\r\n        cost_scaling_factor: 3.0\r\n        inflation_radius: 0.55\r\n      always_send_full_costmap: True\r\n  global_costmap_client:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n  global_costmap_rclcpp_node:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n\r\nmap_server:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    yaml_filename: ""\r\n\r\nmap_saver:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    save_map_timeout: 5.0\r\n    free_thresh_default: 0.25\r\n    occupied_thresh_default: 0.65\r\n    map_subscribe_transient_local: True\r\n\r\nplanner_server:\r\n  ros__parameters:\r\n    expected_planner_frequency: 20.0\r\n    use_sim_time: False\r\n    planner_plugins: ["GridBased"]\r\n    GridBased:\r\n      plugin: "nav2_navfn_planner::NavfnPlanner"\r\n      tolerance: 0.5\r\n      use_astar: false\r\n      allow_unknown: true\r\n\r\nsmoother_server:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    smoother_plugins: ["simple_smoother"]\r\n    simple_smoother:\r\n      plugin: "nav2_smoother::SimpleSmoother"\r\n      tolerance: 1.0e-10\r\n      max_its: 1000\r\n      weight_smooth: 0.9\r\n      weight_data: 0.1\r\n\r\nbehavior_server:\r\n  ros__parameters:\r\n    costmap_topic: local_costmap/costmap_raw\r\n    footprint_topic: local_costmap/published_footprint\r\n    cycle_frequency: 10.0\r\n    behavior_plugins: ["spin", "backup", "drive_on_heading", "wait"]\r\n    spin:\r\n      plugin: "nav2_behaviors::Spin"\r\n      spin_dist: 1.57\r\n    backup:\r\n      plugin: "nav2_behaviors::BackUp"\r\n      backup_dist: 0.15\r\n      backup_speed: 0.025\r\n    drive_on_heading:\r\n      plugin: "nav2_behaviors::DriveOnHeading"\r\n      drive_on_heading_angle_tol: 0.785\r\n      drive_on_heading_forward_dist: 0.5\r\n      drive_on_heading_max_drive_dist: 1.0\r\n    wait:\r\n      plugin: "nav2_behaviors::Wait"\r\n      wait_duration: 1.0\r\n\r\nwaypoint_follower:\r\n  ros__parameters:\r\n    loop_rate: 20\r\n    stop_on_failure: false\r\n    waypoint_task_executor_plugin: "wait_at_waypoint"\r\n    wait_at_waypoint:\r\n      plugin: "nav2_waypoint_follower::WaitAtWaypoint"\r\n      enabled: true\r\n      wait_time: 1\n'})}),"\n",(0,t.jsx)(e.h2,{id:"path-planning-algorithms",children:"Path Planning Algorithms"}),"\n",(0,t.jsx)(e.h3,{id:"global-path-planning",children:"Global Path Planning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\r\nfrom rclpy.node import Node\r\nfrom nav_msgs.msg import Path\r\nfrom geometry_msgs.msg import PoseStamped, Point\r\nfrom sensor_msgs.msg import LaserScan\r\nfrom nav2_msgs.action import ComputePathToPose\r\nfrom rclpy.action import ActionClient\r\nimport numpy as np\r\n\r\nclass Nav2GlobalPlanner(Node):\r\n    def __init__(self):\r\n        super().__init__(\'nav2_global_planner\')\r\n\r\n        # Action client for path computation\r\n        self.path_client = ActionClient(\r\n            self,\r\n            ComputePathToPose,\r\n            \'compute_path_to_pose\'\r\n        )\r\n\r\n        # Publishers\r\n        self.global_path_pub = self.create_publisher(Path, \'/plan\', 10)\r\n\r\n        # Subscribers\r\n        self.goal_sub = self.create_subscription(\r\n            PoseStamped,\r\n            \'/move_base_simple/goal\',\r\n            self.goal_callback,\r\n            10\r\n        )\r\n\r\n        # Internal state\r\n        self.current_path = None\r\n        self.waypoints = []\r\n        self.path_valid = False\r\n\r\n        self.get_logger().info(\'Nav2 Global Planner initialized\')\r\n\r\n    def goal_callback(self, goal_msg):\r\n        """Receive navigation goal and compute path"""\r\n        self.get_logger().info(f\'Received navigation goal: {goal_msg.pose.position.x}, {goal_msg.pose.position.y}\')\r\n\r\n        # Wait for action server\r\n        if not self.path_client.wait_for_server(timeout_sec=1.0):\r\n            self.get_logger().error(\'Path planner action server not available\')\r\n            return\r\n\r\n        # Create goal message\r\n        goal = ComputePathToPose.Goal()\r\n        goal.goal = goal_msg.pose\r\n        goal.planner_id = "GridBased"  # Use Navfn planner\r\n\r\n        # Send goal\r\n        future = self.path_client.send_goal_async(goal)\r\n        future.add_done_callback(self.path_result_callback)\r\n\r\n    def path_result_callback(self, future):\r\n        """Handle path computation result"""\r\n        try:\r\n            goal_handle = future.result()\r\n            if not goal_handle.accepted:\r\n                self.get_logger().info(\'Goal rejected\')\r\n                return\r\n\r\n            self.get_logger().info(\'Goal accepted, getting result...\')\r\n\r\n            result_future = goal_handle.get_result_async()\r\n            result_future.add_done_callback(self.get_path_result)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Exception in path result callback: {e}\')\r\n\r\n    def get_path_result(self, future):\r\n        """Process path result"""\r\n        try:\r\n            result = future.result().result\r\n\r\n            if result.error_code == 0:  # SUCCESS\r\n                self.current_path = result.path\r\n                self.path_valid = True\r\n\r\n                # Publish path\r\n                self.global_path_pub.publish(self.current_path)\r\n\r\n                self.get_logger().info(f\'Computed path with {len(self.current_path.poses)} waypoints\')\r\n\r\n                # Trigger local planner with path\r\n                self.execute_navigation_path()\r\n            else:\r\n                self.get_logger().error(f\'Path computation failed with error code: {result.error_code}\')\r\n                self.path_valid = False\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Exception in get path result: {e}\')\r\n\r\n    def execute_navigation_path(self):\r\n        """Execute navigation along computed path"""\r\n        # This would trigger the BT navigator to follow the path\r\n        # In practice, this integrates with the Nav2 BT navigator\r\n        pass\r\n\r\n    def get_path_to_waypoint(self, start, goal):\r\n        """Get path between start and goal positions"""\r\n        if not self.path_client.wait_for_server(timeout_sec=1.0):\r\n            return None\r\n\r\n        goal_msg = ComputePathToPose.Goal()\r\n        goal_msg.goal.pose.position.x = goal[0]\r\n        goal_msg.goal.pose.position.y = goal[1]\r\n        goal_msg.goal.pose.position.z = 0.0\r\n\r\n        # Set orientation (simple approach)\r\n        goal_msg.goal.pose.orientation.w = 1.0\r\n\r\n        future = self.path_client.send_goal_async(goal_msg)\r\n        future.add_done_callback(lambda f: self.waypoint_path_callback(f, start, goal))\r\n\r\n    def waypoint_path_callback(self, future, start, goal):\r\n        """Handle waypoint path result"""\r\n        try:\r\n            goal_handle = future.result()\r\n            if goal_handle.accepted:\r\n                result_future = goal_handle.get_result_async()\r\n                result_future.add_done_callback(\r\n                    lambda f: self.process_waypoint_result(f, start, goal)\r\n                )\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Waypoint path error: {e}\')\r\n\r\n    def process_waypoint_result(self, future, start, goal):\r\n        """Process waypoint navigation result"""\r\n        try:\r\n            result = future.result().result\r\n            if result.error_code == 0:\r\n                path = result.path\r\n                self.get_logger().info(f\'Waypoint path from {start} to {goal} computed\')\r\n                # Process path as needed\r\n            else:\r\n                self.get_logger().error(f\'Waypoint path computation failed: {result.error_code}\')\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Waypoint result error: {e}\')\n'})}),"\n",(0,t.jsx)(e.h3,{id:"local-path-planning-and-trajectory-generation",children:"Local Path Planning and Trajectory Generation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Twist, PoseStamped\r\nfrom sensor_msgs.msg import LaserScan, PointCloud2\r\nfrom nav_msgs.msg import Path, OccupancyGrid\r\nfrom visualization_msgs.msg import MarkerArray\r\nimport numpy as np\r\nimport math\r\nfrom scipy.spatial import KDTree\r\n\r\nclass Nav2LocalPlanner(Node):\r\n    def __init__(self):\r\n        super().__init__(\'nav2_local_planner\')\r\n\r\n        # Publishers\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        self.local_plan_pub = self.create_publisher(Path, \'/local_plan\', 10)\r\n        self.velocity_marker_pub = self.create_publisher(MarkerArray, \'/velocity_markers\', 10)\r\n\r\n        # Subscribers\r\n        self.odom_sub = self.create_subscription(\r\n            Odometry,\r\n            \'/odom\',\r\n            self.odom_callback,\r\n            10\r\n        )\r\n        self.scan_sub = self.create_subscription(\r\n            LaserScan,\r\n            \'/scan\',\r\n            self.scan_callback,\r\n            10\r\n        )\r\n        self.global_plan_sub = self.create_subscription(\r\n            Path,\r\n            \'/plan\',\r\n            self.global_plan_callback,\r\n            10\r\n        )\r\n        self.local_costmap_sub = self.create_subscription(\r\n            OccupancyGrid,\r\n            \'/local_costmap/costmap\',\r\n            self.costmap_callback,\r\n            10\r\n        )\r\n\r\n        # Parameters\r\n        self.robot_radius = 0.22  # meters\r\n        self.max_linear_vel = 0.5  # m/s\r\n        self.max_angular_vel = 1.0  # rad/s\r\n        self.min_linear_vel = 0.05  # m/s\r\n        self.min_angular_vel = 0.05  # rad/s\r\n        self.controller_frequency = 20.0  # Hz\r\n        self.lookahead_distance = 0.5  # meters\r\n\r\n        # Internal state\r\n        self.current_pose = None\r\n        self.current_velocity = Twist()\r\n        self.global_plan = None\r\n        self.local_plan = Path()\r\n        self.scan_data = None\r\n        self.costmap = None\r\n        self.current_goal_idx = 0\r\n\r\n        # Timer for control loop\r\n        self.control_timer = self.create_timer(\r\n            1.0 / self.controller_frequency,\r\n            self.control_loop\r\n        )\r\n\r\n        self.get_logger().info(\'Nav2 Local Planner initialized\')\r\n\r\n    def odom_callback(self, msg):\r\n        """Update robot pose and velocity from odometry"""\r\n        self.current_pose = msg.pose.pose\r\n        self.current_velocity = msg.twist.twist\r\n\r\n    def scan_callback(self, msg):\r\n        """Process laser scan data for obstacle detection"""\r\n        self.scan_data = msg\r\n\r\n    def global_plan_callback(self, msg):\r\n        """Receive global path and update local planner"""\r\n        self.global_plan = msg\r\n        self.current_goal_idx = 0\r\n        self.get_logger().info(f\'Received global plan with {len(msg.poses)} waypoints\')\r\n\r\n    def costmap_callback(self, msg):\r\n        """Update local costmap"""\r\n        self.costmap = msg\r\n\r\n    def control_loop(self):\r\n        """Main control loop for local navigation"""\r\n        if (self.current_pose is None or\r\n            self.global_plan is None or\r\n            len(self.global_plan.poses) == 0):\r\n            return\r\n\r\n        # Update local plan\r\n        self.update_local_plan()\r\n\r\n        # Generate velocity command\r\n        cmd_vel = self.generate_velocity_command()\r\n\r\n        # Publish command\r\n        self.cmd_vel_pub.publish(cmd_vel)\r\n\r\n        # Publish local plan for visualization\r\n        self.local_plan_pub.publish(self.local_plan)\r\n\r\n    def update_local_plan(self):\r\n        """Update the local navigation plan based on global plan"""\r\n        if self.global_plan is None or len(self.global_plan.poses) == 0:\r\n            return\r\n\r\n        # Find closest point on global path\r\n        closest_idx = self.find_closest_waypoint()\r\n        if closest_idx is None:\r\n            return\r\n\r\n        # Create local plan with lookahead\r\n        local_waypoints = []\r\n        start_idx = max(0, closest_idx)\r\n        end_idx = min(len(self.global_plan.poses),\r\n                      closest_idx + int(self.lookahead_distance / 0.1))  # 0.1m spacing assumption\r\n\r\n        for i in range(start_idx, end_idx):\r\n            local_waypoints.append(self.global_plan.poses[i])\r\n\r\n        # Create local path message\r\n        self.local_plan = Path()\r\n        self.local_plan.header.frame_id = \'map\'\r\n        self.local_plan.header.stamp = self.get_clock().now().to_msg()\r\n        self.local_plan.poses = local_waypoints\r\n\r\n    def find_closest_waypoint(self):\r\n        """Find the closest waypoint on the global path"""\r\n        if (self.current_pose is None or\r\n            self.global_plan is None or\r\n            len(self.global_plan.poses) == 0):\r\n            return None\r\n\r\n        current_pos = np.array([\r\n            self.current_pose.position.x,\r\n            self.current_pose.position.y\r\n        ])\r\n\r\n        min_dist = float(\'inf\')\r\n        closest_idx = 0\r\n\r\n        for i, pose in enumerate(self.global_plan.poses):\r\n            waypoint_pos = np.array([\r\n                pose.pose.position.x,\r\n                pose.pose.position.y\r\n            ])\r\n\r\n            dist = np.linalg.norm(current_pos - waypoint_pos)\r\n            if dist < min_dist:\r\n                min_dist = dist\r\n                closest_idx = i\r\n\r\n        # Update goal index if we\'ve moved past the current target\r\n        if min_dist < 0.5:  # 50cm threshold\r\n            self.current_goal_idx = closest_idx\r\n\r\n        return closest_idx\r\n\r\n    def generate_velocity_command(self):\r\n        """Generate velocity command based on local plan and obstacles"""\r\n        cmd_vel = Twist()\r\n\r\n        if (self.local_plan is None or\r\n            len(self.local_plan.poses) == 0 or\r\n            self.current_pose is None):\r\n            return cmd_vel\r\n\r\n        # Get target waypoint\r\n        target_idx = min(self.current_goal_idx + 1, len(self.local_plan.poses) - 1)\r\n        if target_idx >= len(self.local_plan.poses):\r\n            target_idx = len(self.local_plan.poses) - 1\r\n\r\n        target_pose = self.local_plan.poses[target_idx].pose\r\n        current_pos = np.array([\r\n            self.current_pose.position.x,\r\n            self.current_pose.position.y\r\n        ])\r\n        target_pos = np.array([\r\n            target_pose.position.x,\r\n            target_pose.position.y\r\n        ])\r\n\r\n        # Calculate desired direction\r\n        direction = target_pos - current_pos\r\n        distance = np.linalg.norm(direction)\r\n\r\n        if distance < 0.1:  # Very close to target, slow down\r\n            cmd_vel.linear.x = max(0.05, min(self.max_linear_vel * 0.3, self.current_velocity.linear.x))\r\n        else:\r\n            # Calculate linear velocity based on distance\r\n            cmd_vel.linear.x = min(self.max_linear_vel, distance * 0.5)  # Proportional control\r\n            cmd_vel.linear.x = max(self.min_linear_vel, cmd_vel.linear.x)\r\n\r\n        # Calculate angular velocity for orientation\r\n        desired_yaw = math.atan2(direction[1], direction[0])\r\n\r\n        # Current robot orientation\r\n        current_yaw = self.quaternion_to_yaw(self.current_pose.orientation)\r\n\r\n        # Calculate angle difference\r\n        angle_diff = desired_yaw - current_yaw\r\n        angle_diff = math.atan2(math.sin(angle_diff), math.cos(angle_diff))  # Normalize to [-\u03c0, \u03c0]\r\n\r\n        # Proportional control for angular velocity\r\n        cmd_vel.angular.z = max(-self.max_angular_vel,\r\n                               min(self.max_angular_vel, angle_diff * 1.0))\r\n        cmd_vel.angular.z = max(-self.min_angular_vel,\r\n                               min(self.min_angular_vel, cmd_vel.angular.z))\r\n\r\n        # Check for obstacles using laser scan\r\n        if self.scan_data is not None:\r\n            obstacle_detected = self.check_obstacles(cmd_vel)\r\n            if obstacle_detected:\r\n                # Slow down or stop if obstacle detected\r\n                cmd_vel.linear.x *= 0.3\r\n                cmd_vel.angular.z *= 0.5\r\n\r\n        return cmd_vel\r\n\r\n    def check_obstacles(self, cmd_vel):\r\n        """Check for obstacles in the planned path"""\r\n        if self.scan_data is None:\r\n            return False\r\n\r\n        # Check forward direction (simplified)\r\n        min_angle = -math.pi / 6  # -30 degrees\r\n        max_angle = math.pi / 6   # 30 degrees\r\n\r\n        angle_increment = self.scan_data.angle_increment\r\n        min_idx = int((min_angle - self.scan_data.angle_min) / angle_increment)\r\n        max_idx = int((max_angle - self.scan_data.angle_min) / angle_increment)\r\n\r\n        min_idx = max(0, min_idx)\r\n        max_idx = min(len(self.scan_data.ranges), max_idx)\r\n\r\n        # Check for obstacles within robot radius + safety margin\r\n        safety_margin = 0.3  # meters\r\n        min_distance = self.robot_radius + safety_margin\r\n\r\n        for i in range(min_idx, max_idx):\r\n            if i < len(self.scan_data.ranges):\r\n                range_val = self.scan_data.ranges[i]\r\n                if 0 < range_val < min_distance:\r\n                    return True\r\n\r\n        return False\r\n\r\n    def quaternion_to_yaw(self, quat):\r\n        """Convert quaternion to yaw angle"""\r\n        siny_cosp = 2 * (quat.w * quat.z + quat.x * quat.y)\r\n        cosy_cosp = 1 - 2 * (quat.y * quat.y + quat.z * quat.z)\r\n        return math.atan2(siny_cosp, cosy_cosp)\r\n\r\nclass Nav2BipedalController(Nav2LocalPlanner):\r\n    """\r\n    Specialized controller for bipedal humanoid robots that takes into account\r\n    balance, step constraints, and legged locomotion characteristics\r\n    """\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n        # Bipedal-specific parameters\r\n        self.step_height = 0.05  # meters\r\n        self.step_length = 0.3   # meters\r\n        self.step_frequency = 1.0  # Hz\r\n        self.balance_margin = 0.1  # meters\r\n        self.max_step_deviation = 0.1  # meters\r\n\r\n        # Bipedal state\r\n        self.left_foot_pose = None\r\n        self.right_foot_pose = None\r\n        self.support_foot = \'left\'  # Current support foot\r\n        self.step_phase = 0.0  # Current phase in step cycle (0.0 to 1.0)\r\n\r\n        self.get_logger().info(\'Nav2 Bipedal Controller initialized\')\r\n\r\n    def generate_bipedal_velocity_command(self):\r\n        """Generate velocity command suitable for bipedal locomotion"""\r\n        # First, get the base velocity command\r\n        base_cmd = self.generate_velocity_command()\r\n\r\n        # Adjust for bipedal constraints\r\n        bipedal_cmd = self.adapt_to_bipedal_constraints(base_cmd)\r\n\r\n        return bipedal_cmd\r\n\r\n    def adapt_to_bipedal_constraints(self, base_cmd):\r\n        """Adapt base velocity command to bipedal robot constraints"""\r\n        # Limit acceleration to prevent falls\r\n        max_linear_acc = 0.3  # m/s^2\r\n        max_angular_acc = 0.5  # rad/s^2\r\n\r\n        # Calculate desired accelerations\r\n        desired_linear_acc = (base_cmd.linear.x - self.current_velocity.linear.x) * self.controller_frequency\r\n        desired_angular_acc = (base_cmd.angular.z - self.current_velocity.angular.z) * self.controller_frequency\r\n\r\n        # Limit accelerations\r\n        limited_linear_acc = max(-max_linear_acc, min(max_linear_acc, desired_linear_acc))\r\n        limited_angular_acc = max(-max_angular_acc, min(max_angular_acc, desired_angular_acc))\r\n\r\n        # Calculate limited velocities\r\n        limited_linear_vel = self.current_velocity.linear.x + (limited_linear_acc / self.controller_frequency)\r\n        limited_angular_vel = self.current_velocity.angular.z + (limited_angular_acc / self.controller_frequency)\r\n\r\n        # Apply velocity limits\r\n        result_cmd = Twist()\r\n        result_cmd.linear.x = max(-self.max_linear_vel, min(self.max_linear_vel, limited_linear_vel))\r\n        result_cmd.angular.z = max(-self.max_angular_vel, min(self.max_angular_vel, limited_angular_vel))\r\n\r\n        # Ensure minimum velocities for stable walking\r\n        if abs(result_cmd.linear.x) < self.min_linear_vel and abs(base_cmd.linear.x) > 0.01:\r\n            result_cmd.linear.x = self.min_linear_vel if base_cmd.linear.x > 0 else -self.min_linear_vel\r\n\r\n        if abs(result_cmd.angular.z) < self.min_angular_vel and abs(base_cmd.angular.z) > 0.01:\r\n            result_cmd.angular.z = self.min_angular_vel if base_cmd.angular.z > 0 else -self.min_angular_vel\r\n\r\n        return result_cmd\r\n\r\n    def plan_bipedal_steps(self, target_velocity):\r\n        """Plan bipedal stepping pattern to achieve target velocity"""\r\n        # Calculate step timing based on desired velocity\r\n        if abs(target_velocity.linear.x) > 0.01:\r\n            # Adjust step frequency based on desired speed\r\n            step_freq = max(0.5, min(2.0, 0.5 + abs(target_velocity.linear.x) * 1.0))\r\n        else:\r\n            step_freq = 0.5  # Default standing frequency\r\n\r\n        # Plan step sequence\r\n        step_sequence = []\r\n        current_time = 0.0\r\n        sequence_duration = 2.0  # Plan 2 seconds ahead\r\n\r\n        while current_time < sequence_duration:\r\n            step_info = self.calculate_next_step(current_time, target_velocity)\r\n            step_sequence.append(step_info)\r\n            current_time += 1.0 / step_freq\r\n\r\n        return step_sequence\r\n\r\n    def calculate_next_step(self, time, target_velocity):\r\n        """Calculate the next step based on current state and target velocity"""\r\n        # Calculate desired foot placement based on target velocity\r\n        dt = 1.0 / self.step_frequency  # Time per step\r\n        desired_travel = target_velocity.linear.x * dt\r\n\r\n        # Current support foot position (simplified)\r\n        if self.support_foot == \'left\':\r\n            support_foot_pos = self.left_foot_pose\r\n            swing_foot_pos = self.right_foot_pose\r\n        else:\r\n            support_foot_pos = self.right_foot_pose\r\n            swing_foot_pos = self.left_foot_pose\r\n\r\n        if support_foot_pos is None:\r\n            # Default to current robot position if foot poses unknown\r\n            support_foot_pos = self.current_pose\r\n\r\n        # Calculate next step position\r\n        next_step_x = support_foot_pos.position.x + desired_travel\r\n        next_step_y = support_foot_pos.position.y  # Stay centered laterally\r\n\r\n        # Add some lateral variation for stability\r\n        step_offset = math.sin(time * 2 * math.pi * self.step_frequency) * 0.1\r\n        next_step_y += step_offset\r\n\r\n        # Calculate step trajectory (simplified parabolic arc)\r\n        step_trajectory = self.calculate_step_trajectory(\r\n            swing_foot_pos,\r\n            [next_step_x, next_step_y, support_foot_pos.position.z],\r\n            self.step_height\r\n        )\r\n\r\n        return {\r\n            \'time\': time,\r\n            \'foot\': \'left\' if self.support_foot == \'right\' else \'right\',\r\n            \'position\': [next_step_x, next_step_y, support_foot_pos.position.z],\r\n            \'trajectory\': step_trajectory\r\n        }\r\n\r\n    def calculate_step_trajectory(self, start_pos, end_pos, step_height):\r\n        """Calculate parabolic step trajectory"""\r\n        # Simplified parabolic trajectory for stepping\r\n        trajectory = []\r\n\r\n        start_point = [start_pos.position.x, start_pos.position.y, start_pos.position.z] if start_pos else end_pos\r\n        end_point = end_pos\r\n\r\n        # Calculate intermediate points\r\n        num_points = 10\r\n        for i in range(num_points + 1):\r\n            t = i / num_points  # Parameter from 0 to 1\r\n\r\n            # Parabolic height profile\r\n            height_factor = 4 * t * (1 - t)  # Parabola from 0 to 1 back to 0\r\n            z_offset = height_factor * step_height\r\n\r\n            # Linear interpolation for x,y\r\n            x = start_point[0] + t * (end_point[0] - start_point[0])\r\n            y = start_point[1] + t * (end_point[1] - start_point[1])\r\n            z = start_point[2] + z_offset\r\n\r\n            trajectory.append([x, y, z])\r\n\r\n        return trajectory\n'})}),"\n",(0,t.jsx)(e.h2,{id:"humanoid-specific-navigation-considerations",children:"Humanoid-Specific Navigation Considerations"}),"\n",(0,t.jsx)(e.h3,{id:"bipedal-locomotion-planning",children:"Bipedal Locomotion Planning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import numpy as np\r\nfrom scipy.interpolate import interp1d\r\nimport matplotlib.pyplot as plt\r\n\r\nclass BipedalLocomotionPlanner:\r\n    def __init__(self):\r\n        # Bipedal-specific parameters\r\n        self.step_length = 0.3  # meters\r\n        self.step_width = 0.2   # meters (lateral distance between feet)\r\n        self.step_height = 0.05 # meters (foot clearance)\r\n        self.step_period = 1.0  # seconds per step\r\n        self.com_height = 0.8   # Center of mass height\r\n        self.foot_size = [0.25, 0.1]  # Length x Width of foot\r\n\r\n        # Balance constraints\r\n        self.max_com_deviation = 0.1  # Maximum CoM deviation from foot center\r\n        self.stability_margin = 0.05  # Safety margin for ZMP\r\n\r\n        # Walking pattern parameters\r\n        self.stride_length = 0.3\r\n        self.turning_radius = 1.0\r\n\r\n    def plan_walk_pattern(self, path, start_orientation=0.0):\r\n        \"\"\"Plan bipedal walk pattern along a given path\"\"\"\r\n        footsteps = []\r\n\r\n        # Convert path to step sequence\r\n        path_length = len(path)\r\n        if path_length < 2:\r\n            return footsteps\r\n\r\n        # Calculate total path length\r\n        total_distance = 0\r\n        for i in range(1, path_length):\r\n            dx = path[i][0] - path[i-1][0]\r\n            dy = path[i][1] - path[i-1][1]\r\n            total_distance += np.sqrt(dx*dx + dy*dy)\r\n\r\n        # Plan footsteps based on stride length\r\n        cumulative_distance = 0\r\n        current_pos = np.array(path[0])\r\n        current_orientation = start_orientation\r\n        left_support = True  # Start with left foot support\r\n\r\n        i = 1\r\n        while i < path_length:\r\n            # Calculate direction to next waypoint\r\n            target_pos = np.array(path[i])\r\n            direction = target_pos - current_pos\r\n            distance_to_target = np.linalg.norm(direction)\r\n\r\n            if distance_to_target < self.stride_length:\r\n                # Move to next waypoint\r\n                current_pos = target_pos\r\n                if i < path_length - 1:\r\n                    # Calculate orientation for next segment\r\n                    next_direction = np.array(path[i+1]) - target_pos\r\n                    current_orientation = np.arctan2(next_direction[1], next_direction[0])\r\n                i += 1\r\n            else:\r\n                # Take a step towards the target\r\n                step_direction = direction / distance_to_target\r\n                step_end = current_pos + step_direction * self.stride_length\r\n\r\n                # Determine foot placement (alternating left/right)\r\n                foot_offset = self.calculate_foot_placement(\r\n                    current_orientation,\r\n                    left_support,\r\n                    step_direction\r\n                )\r\n\r\n                foot_pos = step_end + foot_offset\r\n\r\n                # Add footstep\r\n                footsteps.append({\r\n                    'position': foot_pos,\r\n                    'orientation': current_orientation,\r\n                    'foot': 'left' if left_support else 'right',\r\n                    'time': cumulative_distance / self.stride_length * self.step_period\r\n                })\r\n\r\n                # Update state\r\n                current_pos = step_end\r\n                left_support = not left_support\r\n                cumulative_distance += self.stride_length\r\n\r\n        return footsteps\r\n\r\n    def calculate_foot_placement(self, orientation, is_left_foot, step_direction):\r\n        \"\"\"Calculate appropriate foot placement considering balance\"\"\"\r\n        # Calculate lateral offset based on support foot\r\n        lateral_offset = self.step_width / 2\r\n        if is_left_foot:\r\n            # Left foot should be to the left of the CoM path\r\n            perpendicular = np.array([-step_direction[1], step_direction[0]])\r\n        else:\r\n            # Right foot should be to the right of the CoM path\r\n            perpendicular = np.array([step_direction[1], -step_direction[0]])\r\n\r\n        foot_offset = perpendicular * lateral_offset\r\n\r\n        # Apply orientation rotation\r\n        cos_theta = np.cos(orientation)\r\n        sin_theta = np.sin(orientation)\r\n        rotation_matrix = np.array([\r\n            [cos_theta, -sin_theta],\r\n            [sin_theta, cos_theta]\r\n        ])\r\n\r\n        rotated_offset = rotation_matrix @ foot_offset[:2]\r\n\r\n        return np.array([rotated_offset[0], rotated_offset[1], 0])\r\n\r\n    def generate_com_trajectory(self, footsteps):\r\n        \"\"\"Generate Center of Mass trajectory for stable walking\"\"\"\r\n        if not footsteps:\r\n            return []\r\n\r\n        com_trajectory = []\r\n\r\n        # Use inverted pendulum model for CoM motion\r\n        omega = np.sqrt(9.81 / self.com_height)  # Natural frequency\r\n\r\n        for i, footstep in enumerate(footsteps):\r\n            # Calculate CoM position relative to support foot\r\n            # This is a simplified model - real implementation would be more complex\r\n\r\n            # For each step, interpolate CoM position between foot placements\r\n            if i < len(footsteps) - 1:\r\n                next_footstep = footsteps[i + 1]\r\n\r\n                # Generate intermediate CoM positions\r\n                num_interpolations = 10\r\n                for j in range(num_interpolations):\r\n                    t = j / num_interpolations\r\n\r\n                    # Interpolate between current and next footstep\r\n                    current_support = footstep['position']\r\n                    next_support = next_footstep['position']\r\n\r\n                    # CoM follows approximately between feet\r\n                    com_x = current_support[0] + t * (next_support[0] - current_support[0])\r\n                    com_y = current_support[1] + t * (next_support[1] - current_support[1])\r\n\r\n                    # Keep CoM at nominal height\r\n                    com_z = self.com_height\r\n\r\n                    # Add slight oscillation for natural walking\r\n                    oscillation = 0.01 * np.sin(omega * t * self.step_period)\r\n                    com_z += oscillation\r\n\r\n                    com_trajectory.append([com_x, com_y, com_z])\r\n\r\n        return com_trajectory\r\n\r\n    def check_balance_feasibility(self, footsteps):\r\n        \"\"\"Check if the planned footsteps maintain balance\"\"\"\r\n        if len(footsteps) < 2:\r\n            return True\r\n\r\n        # Check Zero Moment Point (ZMP) feasibility\r\n        for i in range(1, len(footsteps)):\r\n            current_step = footsteps[i-1]\r\n            next_step = footsteps[i]\r\n\r\n            # Calculate ZMP between steps\r\n            zmp_x = (current_step['position'][0] + next_step['position'][0]) / 2\r\n            zmp_y = (current_step['position'][1] + next_step['position'][1]) / 2\r\n\r\n            # Check if ZMP is within support polygon\r\n            # For simplicity, check if it's between the two feet\r\n            support_polygon = self.calculate_support_polygon(current_step, next_step)\r\n\r\n            if not self.point_in_polygon([zmp_x, zmp_y], support_polygon):\r\n                return False, f\"ZMP violation at step {i}\"\r\n\r\n        return True, \"Balance feasible\"\r\n\r\n    def calculate_support_polygon(self, current_step, next_step):\r\n        \"\"\"Calculate support polygon for double support phase\"\"\"\r\n        # Simplified rectangular support polygon\r\n        # In reality, this would consider foot shapes and orientations\r\n\r\n        current_foot_center = current_step['position'][:2]\r\n        next_foot_center = next_step['position'][:2]\r\n\r\n        # Calculate rectangle that encompasses both feet\r\n        min_x = min(current_foot_center[0], next_foot_center[0]) - self.foot_size[0]/2\r\n        max_x = max(current_foot_center[0], next_foot_center[0]) + self.foot_size[0]/2\r\n        min_y = min(current_foot_center[1], next_foot_center[1]) - self.foot_size[1]/2\r\n        max_y = max(current_foot_center[1], next_foot_center[1]) + self.foot_size[1]/2\r\n\r\n        return [\r\n            [min_x, min_y],\r\n            [max_x, min_y],\r\n            [max_x, max_y],\r\n            [min_x, max_y]\r\n        ]\r\n\r\n    def point_in_polygon(self, point, polygon):\r\n        \"\"\"Check if a point is inside a polygon using ray casting\"\"\"\r\n        x, y = point\r\n        n = len(polygon)\r\n        inside = False\r\n\r\n        p1x, p1y = polygon[0]\r\n        for i in range(1, n + 1):\r\n            p2x, p2y = polygon[i % n]\r\n            if y > min(p1y, p2y):\r\n                if y <= max(p1y, p2y):\r\n                    if x <= max(p1x, p2x):\r\n                        if p1y != p2y:\r\n                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\r\n                        if p1x == p2x or x <= xinters:\r\n                            inside = not inside\r\n            p1x, p1y = p2x, p2y\r\n\r\n        return inside\r\n\r\n    def visualize_walk_pattern(self, path, footsteps, com_trajectory):\r\n        \"\"\"Visualize the planned walk pattern\"\"\"\r\n        fig, ax = plt.subplots(figsize=(12, 8))\r\n\r\n        # Plot path\r\n        path_array = np.array(path)\r\n        ax.plot(path_array[:, 0], path_array[:, 1], 'b-', linewidth=2, label='Desired Path')\r\n\r\n        # Plot footsteps\r\n        left_footsteps = [f for f in footsteps if f['foot'] == 'left']\r\n        right_footsteps = [f for f in footsteps if f['foot'] == 'right']\r\n\r\n        if left_footsteps:\r\n            left_array = np.array([f['position'] for f in left_footsteps])\r\n            ax.scatter(left_array[:, 0], left_array[:, 1], c='red', s=100, label='Left Foot', zorder=5)\r\n\r\n        if right_footsteps:\r\n            right_array = np.array([f['position'] for f in right_footsteps])\r\n            ax.scatter(right_array[:, 0], right_array[:, 1], c='blue', s=100, label='Right Foot', zorder=5)\r\n\r\n        # Plot CoM trajectory\r\n        if com_trajectory:\r\n            com_array = np.array(com_trajectory)\r\n            ax.plot(com_array[:, 0], com_array[:, 1], 'g--', linewidth=1, label='CoM Trajectory')\r\n\r\n        ax.set_xlabel('X (m)')\r\n        ax.set_ylabel('Y (m)')\r\n        ax.set_title('Bipedal Walk Pattern Planning')\r\n        ax.legend()\r\n        ax.grid(True, alpha=0.3)\r\n        ax.axis('equal')\r\n\r\n        plt.tight_layout()\r\n        plt.show()\r\n\r\ndef main():\r\n    # Example usage of bipedal locomotion planner\r\n    planner = BipedalLocomotionPlanner()\r\n\r\n    # Define a simple path\r\n    path = [\r\n        [0, 0],\r\n        [1, 0],\r\n        [2, 0.5],\r\n        [3, 1],\r\n        [4, 1.5],\r\n        [5, 1.5]\r\n    ]\r\n\r\n    # Plan footsteps\r\n    footsteps = planner.plan_walk_pattern(path)\r\n\r\n    # Generate CoM trajectory\r\n    com_trajectory = planner.generate_com_trajectory(footsteps)\r\n\r\n    # Check balance feasibility\r\n    is_balanced, message = planner.check_balance_feasibility(footsteps)\r\n    print(f\"Balance check: {message}\")\r\n\r\n    # Visualize results\r\n    # planner.visualize_walk_pattern(path, footsteps, com_trajectory)\r\n\r\n    print(f\"Planned {len(footsteps)} footsteps for the path\")\r\n    print(f\"Generated CoM trajectory with {len(com_trajectory)} points\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-perception-systems",children:"Integration with Perception Systems"}),"\n",(0,t.jsx)(e.h3,{id:"sensor-integration-for-navigation",children:"Sensor Integration for Navigation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import LaserScan, PointCloud2, Image\r\nfrom geometry_msgs.msg import PoseStamped\r\nfrom nav_msgs.msg import OccupancyGrid\r\nfrom visualization_msgs.msg import MarkerArray\r\nfrom std_msgs.msg import Bool\r\nimport numpy as np\r\nimport cv2\r\nfrom cv_bridge import CvBridge\r\n\r\nclass PerceptionIntegratedNavigator(Node):\r\n    def __init__(self):\r\n        super().__init__(\'perception_integrated_navigator\')\r\n\r\n        # Initialize CV bridge\r\n        self.cv_bridge = CvBridge()\r\n\r\n        # Publishers\r\n        self.obstacle_warning_pub = self.create_publisher(Bool, \'/obstacle_warning\', 10)\r\n        self.navigation_status_pub = self.create_publisher(String, \'/navigation_status\', 10)\r\n        self.perception_markers_pub = self.create_publisher(MarkerArray, \'/perception_markers\', 10)\r\n\r\n        # Subscribers\r\n        self.laser_sub = self.create_subscription(\r\n            LaserScan,\r\n            \'/scan\',\r\n            self.laser_callback,\r\n            10\r\n        )\r\n        self.depth_sub = self.create_subscription(\r\n            Image,\r\n            \'/camera/depth/image_rect_raw\',\r\n            self.depth_callback,\r\n            10\r\n        )\r\n        self.rgb_sub = self.create_subscription(\r\n            Image,\r\n            \'/camera/rgb/image_rect_color\',\r\n            self.rgb_callback,\r\n            10\r\n        )\r\n        self.imu_sub = self.create_subscription(\r\n            Imu,\r\n            \'/imu/data\',\r\n            self.imu_callback,\r\n            10\r\n        )\r\n        self.odom_sub = self.create_subscription(\r\n            Odometry,\r\n            \'/odom\',\r\n            self.odom_callback,\r\n            10\r\n        )\r\n\r\n        # Perception-integrated navigation components\r\n        self.obstacle_detector = ObstacleDetector()\r\n        self.terrain_classifier = TerrainClassifier()\r\n        self.dynamic_object_tracker = DynamicObjectTracker()\r\n\r\n        # Navigation state\r\n        self.current_pose = None\r\n        self.current_velocity = None\r\n        self.imu_data = None\r\n        self.depth_image = None\r\n        self.rgb_image = None\r\n        self.laser_data = None\r\n\r\n        # Navigation safety parameters\r\n        self.safety_distance = 0.5  # meters\r\n        self.dynamic_object_buffer = 0.8  # meters\r\n        self.rough_terrain_penalty = 2.0  # multiplier for cost\r\n\r\n        # Timer for perception processing\r\n        self.perception_timer = self.create_timer(0.1, self.perception_processing_loop)\r\n\r\n        self.get_logger().info(\'Perception-Integrated Navigator initialized\')\r\n\r\n    def laser_callback(self, msg):\r\n        """Process laser scan data"""\r\n        self.laser_data = msg\r\n        obstacles = self.obstacle_detector.detect_from_laser(msg)\r\n        self.update_costmap_with_obstacles(obstacles)\r\n\r\n    def depth_callback(self, msg):\r\n        """Process depth image data"""\r\n        try:\r\n            self.depth_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding=\'passthrough\')\r\n\r\n            # Extract 3D obstacles from depth\r\n            obstacles_3d = self.obstacle_detector.detect_from_depth(self.depth_image)\r\n            self.update_costmap_with_3d_obstacles(obstacles_3d)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing depth image: {e}\')\r\n\r\n    def rgb_callback(self, msg):\r\n        """Process RGB image data for semantic understanding"""\r\n        try:\r\n            self.rgb_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\r\n\r\n            # Classify terrain and detect semantic obstacles\r\n            terrain_classification = self.terrain_classifier.classify_from_image(self.rgb_image)\r\n            semantic_obstacles = self.obstacle_detector.detect_semantic_obstacles(self.rgb_image)\r\n\r\n            # Update navigation with semantic information\r\n            self.update_navigation_with_semantics(terrain_classification, semantic_obstacles)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing RGB image: {e}\')\r\n\r\n    def imu_callback(self, msg):\r\n        """Process IMU data for balance and orientation"""\r\n        self.imu_data = msg\r\n\r\n        # Check for tilt that might affect navigation\r\n        roll, pitch, yaw = self.quaternion_to_euler(msg.orientation)\r\n\r\n        # If robot is tilted beyond safe limits, pause navigation\r\n        max_tilt = 0.3  # radians (~17 degrees)\r\n        if abs(roll) > max_tilt or abs(pitch) > max_tilt:\r\n            self.pause_navigation("Robot tilt unsafe")\r\n\r\n    def odom_callback(self, msg):\r\n        """Update pose and velocity for navigation"""\r\n        self.current_pose = msg.pose.pose\r\n        self.current_velocity = msg.twist.twist\r\n\r\n    def perception_processing_loop(self):\r\n        """Main loop for processing perception data and updating navigation"""\r\n        if self.current_pose is None:\r\n            return\r\n\r\n        # Process all sensor data\r\n        self.process_fusion_data()\r\n\r\n        # Update navigation plan based on perception\r\n        self.update_navigation_plan()\r\n\r\n        # Check safety conditions\r\n        self.check_navigation_safety()\r\n\r\n    def process_fusion_data(self):\r\n        """Fuse data from multiple sensors"""\r\n        if (self.laser_data is not None and\r\n            self.depth_image is not None and\r\n            self.rgb_image is not None):\r\n\r\n            # Fuse obstacle detections\r\n            laser_obstacles = self.obstacle_detector.detect_from_laser(self.laser_data)\r\n            depth_obstacles = self.obstacle_detector.detect_from_depth(self.depth_image)\r\n            visual_obstacles = self.obstacle_detector.detect_semantic_obstacles(self.rgb_image)\r\n\r\n            # Combine obstacle detections with confidence weighting\r\n            fused_obstacles = self.fuse_obstacle_detections(\r\n                laser_obstacles, depth_obstacles, visual_obstacles\r\n            )\r\n\r\n            # Update costmap with fused obstacles\r\n            self.update_costmap_with_fused_obstacles(fused_obstacles)\r\n\r\n    def fuse_obstacle_detections(self, laser_obs, depth_obs, visual_obs):\r\n        """Fuse obstacle detections from multiple sensors"""\r\n        fused_obstacles = []\r\n\r\n        # Confidence weights for different sensors\r\n        laser_weight = 0.8\r\n        depth_weight = 0.9\r\n        visual_weight = 0.7\r\n\r\n        # Create obstacle dictionary with weighted confidences\r\n        obstacle_dict = {}\r\n\r\n        # Add laser obstacles\r\n        for obs in laser_obs:\r\n            pos_key = (round(obs[\'x\'], 2), round(obs[\'y\'], 2))\r\n            if pos_key not in obstacle_dict:\r\n                obstacle_dict[pos_key] = {\'confidence\': 0, \'type\': \'unknown\'}\r\n            obstacle_dict[pos_key][\'confidence\'] += laser_obs[\'confidence\'] * laser_weight\r\n            if \'laser\' not in obstacle_dict[pos_key][\'type\']:\r\n                obstacle_dict[pos_key][\'type\'] += \'_laser\'\r\n\r\n        # Add depth obstacles\r\n        for obs in depth_obs:\r\n            pos_key = (round(obs[\'x\'], 2), round(obs[\'y\'], 2))\r\n            if pos_key not in obstacle_dict:\r\n                obstacle_dict[pos_key] = {\'confidence\': 0, \'type\': \'unknown\'}\r\n            obstacle_dict[pos_key][\'confidence\'] += obs[\'confidence\'] * depth_weight\r\n            if \'depth\' not in obstacle_dict[pos_key][\'type\']:\r\n                obstacle_dict[pos_key][\'type\'] += \'_depth\'\r\n\r\n        # Add visual obstacles\r\n        for obs in visual_obs:\r\n            pos_key = (round(obs[\'x\'], 2), round(obs[\'y\'], 2))\r\n            if pos_key not in obstacle_dict:\r\n                obstacle_dict[pos_key] = {\'confidence\': 0, \'type\': obs.get(\'class\', \'unknown\')}\r\n            obstacle_dict[pos_key][\'confidence\'] += obs[\'confidence\'] * visual_weight\r\n\r\n        # Create fused obstacle list\r\n        for pos_key, data in obstacle_dict.items():\r\n            if data[\'confidence\'] > 0.5:  # Threshold for valid obstacle\r\n                fused_obstacles.append({\r\n                    \'x\': pos_key[0],\r\n                    \'y\': pos_key[1],\r\n                    \'confidence\': data[\'confidence\'],\r\n                    \'type\': data[\'type\']\r\n                })\r\n\r\n        return fused_obstacles\r\n\r\n    def update_costmap_with_fused_obstacles(self, obstacles):\r\n        """Update costmap with fused obstacle data"""\r\n        # This would update the Nav2 costmap with obstacle information\r\n        # In practice, this integrates with the Nav2 costmap server\r\n\r\n        # For now, just log the obstacles\r\n        for obs in obstacles:\r\n            self.get_logger().debug(f"Fused obstacle: {obs}")\r\n\r\n    def update_navigation_with_semantics(self, terrain_class, semantic_obstacles):\r\n        """Update navigation based on semantic understanding"""\r\n        # Adjust navigation parameters based on terrain classification\r\n        if terrain_class[\'roughness\'] > 0.7:  # Very rough terrain\r\n            # Reduce speed and increase safety margins\r\n            self.reduce_navigation_speed(0.5)\r\n            self.increase_safety_margin(0.3)\r\n        elif terrain_class[\'slope\'] > 0.3:  # Steep slope\r\n            # Use different navigation strategy for slopes\r\n            self.adapt_to_slope_navigation(terrain_class[\'slope\'])\r\n\r\n        # Handle semantic obstacles differently\r\n        for obs in semantic_obstacles:\r\n            if obs[\'class\'] == \'person\':\r\n                # Maintain larger safety buffer for people\r\n                self.increase_dynamic_buffer(1.0)\r\n            elif obs[\'class\'] == \'vehicle\':\r\n                # Be especially cautious around vehicles\r\n                self.activate_caution_mode()\r\n            elif obs[\'class\'] == \'fragile_object\':\r\n                # Navigate carefully around fragile objects\r\n                self.enable_delicate_navigation()\r\n\r\n    def check_navigation_safety(self):\r\n        """Check if navigation is currently safe"""\r\n        safety_issues = []\r\n\r\n        # Check for immediate obstacles\r\n        if self.laser_data:\r\n            min_range = min(self.laser_data.ranges) if self.laser_data.ranges else float(\'inf\')\r\n            if min_range < self.safety_distance:\r\n                safety_issues.append(f"Obstacle too close: {min_range:.2f}m < {self.safety_distance:.2f}m")\r\n\r\n        # Check for dynamic obstacles\r\n        if self.dynamic_object_tracker.has_objects_approaching():\r\n            safety_issues.append("Approaching dynamic object detected")\r\n\r\n        # Check IMU for unsafe tilt\r\n        if (self.imu_data and\r\n            (abs(self.quaternion_to_euler(self.imu_data.orientation)[0]) > 0.4 or\r\n             abs(self.quaternion_to_euler(self.imu_data.orientation)[1]) > 0.4)):\r\n            safety_issues.append("Unsafe robot orientation detected")\r\n\r\n        # Publish safety status\r\n        if safety_issues:\r\n            self.get_logger().warn(f"Navigation safety issues: {\', \'.join(safety_issues)}")\r\n            self.publish_safety_warning(safety_issues)\r\n        else:\r\n            self.get_logger().info("Navigation is safe")\r\n\r\n    def publish_safety_warning(self, issues):\r\n        """Publish safety warnings"""\r\n        warning_msg = Bool()\r\n        warning_msg.data = True\r\n        self.obstacle_warning_pub.publish(warning_msg)\r\n\r\n        status_msg = String()\r\n        status_msg.data = f"Safety issues: {\', \'.join(issues)}"\r\n        self.navigation_status_pub.publish(status_msg)\r\n\r\n    def quaternion_to_euler(self, quat):\r\n        """Convert quaternion to Euler angles"""\r\n        import math\r\n        # Convert quaternion to Euler angles (roll, pitch, yaw)\r\n        sinr_cosp = 2 * (quat.w * quat.x + quat.y * quat.z)\r\n        cosr_cosp = 1 - 2 * (quat.x * quat.x + quat.y * quat.y)\r\n        roll = math.atan2(sinr_cosp, cosr_cosp)\r\n\r\n        sinp = 2 * (quat.w * quat.y - quat.z * quat.x)\r\n        pitch = math.asin(sinp)\r\n\r\n        siny_cosp = 2 * (quat.w * quat.z + quat.x * quat.y)\r\n        cosy_cosp = 1 - 2 * (quat.y * quat.y + quat.z * quat.z)\r\n        yaw = math.atan2(siny_cosp, cosy_cosp)\r\n\r\n        return roll, pitch, yaw\r\n\r\n    def reduce_navigation_speed(self, factor):\r\n        """Reduce navigation speed by factor"""\r\n        # This would integrate with the Nav2 controller to reduce speeds\r\n        pass\r\n\r\n    def increase_safety_margin(self, additional_margin):\r\n        """Increase safety margin by additional amount"""\r\n        self.safety_distance += additional_margin\r\n\r\n    def adapt_to_slope_navigation(self, slope_angle):\r\n        """Adapt navigation for sloped terrain"""\r\n        # Adjust footstep planning for slopes\r\n        # Modify balance control parameters\r\n        pass\r\n\r\n    def increase_dynamic_buffer(self, additional_buffer):\r\n        """Increase buffer for dynamic objects"""\r\n        self.dynamic_object_buffer += additional_buffer\r\n\r\n    def activate_caution_mode(self):\r\n        """Activate cautious navigation mode"""\r\n        self.reduce_navigation_speed(0.3)\r\n        self.increase_safety_margin(0.5)\r\n\r\n    def enable_delicate_navigation(self):\r\n        """Enable delicate navigation around fragile objects"""\r\n        self.reduce_navigation_speed(0.2)\r\n        self.increase_safety_margin(0.8)\r\n\r\nclass ObstacleDetector:\r\n    def __init__(self):\r\n        # Initialize obstacle detection models\r\n        pass\r\n\r\n    def detect_from_laser(self, laser_msg):\r\n        """Detect obstacles from laser scan"""\r\n        obstacles = []\r\n\r\n        for i, range_val in enumerate(laser_msg.ranges):\r\n            if 0 < range_val < 3.0:  # Valid range measurement\r\n                angle = laser_msg.angle_min + i * laser_msg.angle_increment\r\n                x = range_val * np.cos(angle)\r\n                y = range_val * np.sin(angle)\r\n\r\n                obstacles.append({\r\n                    \'x\': x,\r\n                    \'y\': y,\r\n                    \'range\': range_val,\r\n                    \'angle\': angle,\r\n                    \'confidence\': 0.9  # High confidence for laser\r\n                })\r\n\r\n        return obstacles\r\n\r\n    def detect_from_depth(self, depth_image):\r\n        """Detect 3D obstacles from depth image"""\r\n        obstacles = []\r\n\r\n        # Simple threshold-based obstacle detection\r\n        valid_depths = depth_image[depth_image > 0]\r\n        if len(valid_depths) > 0:\r\n            min_depth = np.min(valid_depths)\r\n            if min_depth < 2.0:  # Something is close\r\n                # Convert pixel coordinates to world coordinates\r\n                # This is simplified - real implementation would use camera parameters\r\n                height, width = depth_image.shape\r\n                for u in range(0, width, 10):  # Sample every 10 pixels\r\n                    for v in range(0, height, 10):\r\n                        depth_val = depth_image[v, u]\r\n                        if 0 < depth_val < 2.0:\r\n                            # Convert to world coordinates (simplified)\r\n                            x = (u - width/2) * depth_val * 0.001  # Rough conversion\r\n                            y = (v - height/2) * depth_val * 0.001\r\n\r\n                            obstacles.append({\r\n                                \'x\': x,\r\n                                \'y\': y,\r\n                                \'z\': depth_val,\r\n                                \'confidence\': 0.7\r\n                            })\r\n\r\n        return obstacles\r\n\r\n    def detect_semantic_obstacles(self, rgb_image):\r\n        """Detect semantic obstacles from RGB image"""\r\n        # This would use a trained CNN for semantic segmentation\r\n        # For now, return empty list\r\n        return []\r\n\r\nclass TerrainClassifier:\r\n    def __init__(self):\r\n        # Initialize terrain classification models\r\n        pass\r\n\r\n    def classify_from_image(self, rgb_image):\r\n        """Classify terrain type from RGB image"""\r\n        # Analyze image texture, color, and structure\r\n        gray = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)\r\n\r\n        # Calculate texture metrics\r\n        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\r\n\r\n        # Estimate roughness (higher variance = rougher texture)\r\n        roughness = min(1.0, laplacian_var / 1000.0)\r\n\r\n        # Estimate slope from apparent texture compression\r\n        # This is a very simplified approach\r\n        slope = 0.1  # Default assumption\r\n\r\n        return {\r\n            \'roughness\': roughness,\r\n            \'slope\': slope,\r\n            \'traversability\': 1.0 - roughness  # Simplified traversability\r\n        }\r\n\r\nclass DynamicObjectTracker:\r\n    def __init__(self):\r\n        # Initialize tracking algorithms\r\n        self.tracked_objects = []\r\n        self.motion_threshold = 0.1  # m/s\r\n\r\n    def has_objects_approaching(self):\r\n        """Check if any tracked objects are approaching the robot"""\r\n        # Check if any tracked object\'s velocity vector points toward robot\r\n        # This is a simplified implementation\r\n        return False\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"navigation-performance-tuning",children:"Navigation Performance Tuning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import psutil\r\nimport time\r\nfrom collections import deque\r\nimport threading\r\n\r\nclass Nav2PerformanceOptimizer:\r\n    def __init__(self):\r\n        self.cpu_usage_history = deque(maxlen=100)\r\n        self.memory_usage_history = deque(maxlen=100)\r\n        self.nav_frequency_history = deque(maxlen=100)\r\n        self.path_computation_times = deque(maxlen=50)\r\n\r\n        self.target_frequency = 20.0  # Hz\r\n        self.max_cpu_percent = 80.0   # Percent\r\n        self.adaptive_params = {\r\n            'planner_frequency': 20.0,\r\n            'controller_frequency': 20.0,\r\n            'costmap_resolution': 0.05,\r\n            'max_planning_time': 5.0\r\n        }\r\n\r\n        self.performance_lock = threading.Lock()\r\n        self.monitoring_active = True\r\n\r\n        # Start performance monitoring thread\r\n        self.monitor_thread = threading.Thread(target=self.performance_monitor_loop)\r\n        self.monitor_thread.daemon = True\r\n        self.monitor_thread.start()\r\n\r\n    def performance_monitor_loop(self):\r\n        \"\"\"Continuous performance monitoring\"\"\"\r\n        while self.monitoring_active:\r\n            # Monitor system resources\r\n            cpu_percent = psutil.cpu_percent(interval=0.1)\r\n            memory_percent = psutil.virtual_memory().percent\r\n\r\n            with self.performance_lock:\r\n                self.cpu_usage_history.append(cpu_percent)\r\n                self.memory_usage_history.append(memory_percent)\r\n\r\n            # Adjust navigation parameters based on performance\r\n            self.adjust_parameters_for_performance()\r\n\r\n            time.sleep(0.5)  # Monitor every 0.5 seconds\r\n\r\n    def adjust_parameters_for_performance(self):\r\n        \"\"\"Dynamically adjust navigation parameters based on performance\"\"\"\r\n        with self.performance_lock:\r\n            if not self.cpu_usage_history:\r\n                return\r\n\r\n            avg_cpu = sum(self.cpu_usage_history) / len(self.cpu_usage_history)\r\n            avg_memory = sum(self.memory_usage_history) / len(self.memory_usage_history)\r\n\r\n        # If CPU usage is high, reduce computation intensity\r\n        if avg_cpu > self.max_cpu_percent:\r\n            self.reduce_computational_load()\r\n        elif avg_cpu < self.max_cpu_percent * 0.6:\r\n            # If CPU usage is low, we can afford more computation\r\n            self.increase_computational_load()\r\n\r\n    def reduce_computational_load(self):\r\n        \"\"\"Reduce computational load to improve performance\"\"\"\r\n        # Reduce planner frequency\r\n        self.adaptive_params['planner_frequency'] = max(5.0,\r\n            self.adaptive_params['planner_frequency'] * 0.8)\r\n\r\n        # Increase costmap resolution (larger cells = less computation)\r\n        self.adaptive_params['costmap_resolution'] = min(0.2,\r\n            self.adaptive_params['costmap_resolution'] * 1.2)\r\n\r\n        # Reduce maximum planning time\r\n        self.adaptive_params['max_planning_time'] = max(1.0,\r\n            self.adaptive_params['max_planning_time'] * 0.8)\r\n\r\n        print(f\"Reduced computational load: freq={self.adaptive_params['planner_frequency']:.1f}Hz, \"\r\n              f\"res={self.adaptive_params['costmap_resolution']:.2f}m\")\r\n\r\n    def increase_computational_load(self):\r\n        \"\"\"Increase computational load for better performance\"\"\"\r\n        # Increase planner frequency\r\n        self.adaptive_params['planner_frequency'] = min(30.0,\r\n            self.adaptive_params['planner_frequency'] * 1.1)\r\n\r\n        # Decrease costmap resolution (smaller cells = more precision)\r\n        self.adaptive_params['costmap_resolution'] = max(0.02,\r\n            self.adaptive_params['costmap_resolution'] * 0.9)\r\n\r\n        # Increase maximum planning time\r\n        self.adaptive_params['max_planning_time'] = min(10.0,\r\n            self.adaptive_params['max_planning_time'] * 1.1)\r\n\r\n        print(f\"Increased computational load: freq={self.adaptive_params['planner_frequency']:.1f}Hz, \"\r\n              f\"res={self.adaptive_params['costmap_resolution']:.2f}m\")\r\n\r\n    def get_performance_metrics(self):\r\n        \"\"\"Get current performance metrics\"\"\"\r\n        with self.performance_lock:\r\n            if not self.cpu_usage_history:\r\n                return {}\r\n\r\n            metrics = {\r\n                'cpu_percent': sum(self.cpu_usage_history) / len(self.cpu_usage_history),\r\n                'memory_percent': sum(self.memory_usage_history) / len(self.memory_usage_history),\r\n                'current_params': self.adaptive_params.copy()\r\n            }\r\n\r\n        if self.nav_frequency_history:\r\n            metrics['actual_frequency'] = sum(self.nav_frequency_history) / len(self.nav_frequency_history)\r\n\r\n        if self.path_computation_times:\r\n            metrics['avg_path_time'] = sum(self.path_computation_times) / len(self.path_computation_times)\r\n            metrics['max_path_time'] = max(self.path_computation_times)\r\n\r\n        return metrics\r\n\r\n    def stop_monitoring(self):\r\n        \"\"\"Stop performance monitoring\"\"\"\r\n        self.monitoring_active = False\r\n        if self.monitor_thread:\r\n            self.monitor_thread.join(timeout=1.0)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-and-best-practices",children:"Troubleshooting and Best Practices"}),"\n",(0,t.jsx)(e.h3,{id:"common-navigation-issues-and-solutions",children:"Common Navigation Issues and Solutions"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class Nav2Troubleshooter:\r\n    def __init__(self):\r\n        self.known_issues = {\r\n            'oscillation': {\r\n                'symptoms': ['robot moves back and forth', 'cannot reach goal'],\r\n                'causes': ['narrow passages', 'incorrect costmap inflation'],\r\n                'solutions': [\r\n                    'increase inflation radius',\r\n                    'adjust controller parameters',\r\n                    'modify global planner tolerance'\r\n                ]\r\n            },\r\n            'getting_stuck': {\r\n                'symptoms': ['robot stops moving', 'high cmd_vel commands'],\r\n                'causes': ['local minima', 'incorrect localization'],\r\n                'solutions': [\r\n                    'enable recovery behaviors',\r\n                    'improve sensor coverage',\r\n                    'adjust costmap obstacles'\r\n                ]\r\n            },\r\n            'planning_failure': {\r\n                'symptoms': ['no path found', 'global planner fails'],\r\n                'causes': ['map issues', 'incorrect frame transforms'],\r\n                'solutions': [\r\n                    'verify map quality',\r\n                    'check tf tree',\r\n                    'adjust planner parameters'\r\n                ]\r\n            }\r\n        }\r\n\r\n    def diagnose_issue(self, symptoms):\r\n        \"\"\"Diagnose navigation issue based on symptoms\"\"\"\r\n        possible_issues = []\r\n\r\n        for issue_name, issue_info in self.known_issues.items():\r\n            symptom_match = 0\r\n            for symptom in symptoms:\r\n                for known_symptom in issue_info['symptoms']:\r\n                    if symptom.lower() in known_symptom.lower():\r\n                        symptom_match += 1\r\n\r\n            if symptom_match > 0:\r\n                possible_issues.append({\r\n                    'issue': issue_name,\r\n                    'confidence': symptom_match / len(issue_info['symptoms']),\r\n                    'solutions': issue_info['solutions']\r\n                })\r\n\r\n        return possible_issues\r\n\r\n    def get_configuration_checklist(self):\r\n        \"\"\"Get checklist for Nav2 configuration verification\"\"\"\r\n        checklist = [\r\n            \"Verify tf tree is complete and transforms are broadcasting\",\r\n            \"Check that costmaps are updating and not static\",\r\n            \"Ensure robot radius/footprint is correctly configured\",\r\n            \"Verify sensor data is being received and processed\",\r\n            \"Confirm global and local planners are loaded correctly\",\r\n            \"Check that controllers are properly configured\",\r\n            \"Validate behavior tree is executing as expected\",\r\n            \"Ensure proper frame IDs are used throughout\",\r\n            \"Test localization system independently\",\r\n            \"Verify map is properly loaded and aligned\"\r\n        ]\r\n        return checklist\r\n\r\n    def performance_tuning_guide(self):\r\n        \"\"\"Provide performance tuning recommendations\"\"\"\r\n        guide = {\r\n            'frequency_tuning': {\r\n                'global_planner': '5-10 Hz is typically sufficient',\r\n                'local_planner': '20-50 Hz for responsive control',\r\n                'costmap_updates': '5-10 Hz for local, 1 Hz for global'\r\n            },\r\n            'memory_optimization': {\r\n                'costmap_sizes': 'Keep local costmap small (3-5m)',\r\n                'resolution_tradeoffs': '0.025-0.05m for local, 0.1-0.2m for global',\r\n                'layer_management': 'Remove unused costmap layers'\r\n            },\r\n            'computation_balancing': {\r\n                'planning_vs_control': 'Separate heavy planning from control loops',\r\n                'multi_threading': 'Use separate threads for perception and navigation',\r\n                'load_distribution': 'Distribute computations across available cores'\r\n            }\r\n        }\r\n        return guide\n"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives-review",children:"Learning Objectives Review"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand Nav2 architecture and components \u2713"}),"\n",(0,t.jsx)(e.li,{children:"Configure Nav2 for humanoid robotics applications \u2713"}),"\n",(0,t.jsx)(e.li,{children:"Implement path planning algorithms for bipedal locomotion \u2713"}),"\n",(0,t.jsx)(e.li,{children:"Integrate perception systems with navigation \u2713"}),"\n",(0,t.jsx)(e.li,{children:"Optimize navigation for dynamic environments \u2713"}),"\n",(0,t.jsx)(e.li,{children:"Troubleshoot common navigation issues \u2713"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"practical-exercise",children:"Practical Exercise"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Install and configure Nav2 for your robot platform"}),"\n",(0,t.jsx)(e.li,{children:"Set up the necessary configuration files and launch files"}),"\n",(0,t.jsx)(e.li,{children:"Implement a basic navigation system with path planning"}),"\n",(0,t.jsx)(e.li,{children:"Integrate perception data (laser, camera, IMU) for enhanced navigation"}),"\n",(0,t.jsx)(e.li,{children:"Test navigation in both simulation and real environments"}),"\n",(0,t.jsx)(e.li,{children:"Fine-tune parameters for optimal performance"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Explain the key differences between Nav2 and the legacy ROS navigation stack."}),"\n",(0,t.jsx)(e.li,{children:"What are the main components of the Nav2 architecture?"}),"\n",(0,t.jsx)(e.li,{children:"How does the Behavior Tree system improve navigation flexibility?"}),"\n",(0,t.jsx)(e.li,{children:"What are the special considerations for bipedal robot navigation compared to wheeled robots?"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Nav2 Documentation: ",(0,t.jsx)(e.a,{href:"https://navigation.ros.org/",children:"https://navigation.ros.org/"})]}),"\n",(0,t.jsx)(e.li,{children:'"The Navigation Stack for ROS" by Eitan Marder-Eppstein'}),"\n",(0,t.jsx)(e.li,{children:'"Path Planning in Complex Environments" by Choset et al.'}),"\n",(0,t.jsxs)(e.li,{children:["Behavior Trees in Robotics: ",(0,t.jsx)(e.a,{href:"https://arxiv.org/abs/1709.00084",children:"https://arxiv.org/abs/1709.00084"})]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(e.p,{children:["Continue to ",(0,t.jsx)(e.a,{href:"/physical-ai/docs/module-3/sim-to-real",children:"Sim-to-Real Transfer"})," to learn about transferring AI models from simulation to real robots."]})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(c,{...n})}):c(n)}},8453(n,e,r){r.d(e,{R:()=>s,x:()=>i});var a=r(6540);const t={},o=a.createContext(t);function s(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),a.createElement(o.Provider,{value:e},n.children)}}}]);