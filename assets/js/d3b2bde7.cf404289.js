"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[794],{8453(n,e,r){r.d(e,{R:()=>o,x:()=>s});var i=r(6540);const a={},t=i.createContext(a);function o(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),i.createElement(t.Provider,{value:e},n.children)}},8893(n,e,r){r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-3/isaac-sim","title":"Isaac Sim","description":"Comprehensive guide to NVIDIA Isaac Sim for photorealistic robotics simulation","source":"@site/docs/module-3/isaac-sim.md","sourceDirName":"module-3","slug":"/module-3/isaac-sim","permalink":"/physical-ai/docs/module-3/isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-textbook/book-ai/tree/main/docs/module-3/isaac-sim.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"isaac-sim","title":"Isaac Sim","sidebar_position":3,"description":"Comprehensive guide to NVIDIA Isaac Sim for photorealistic robotics simulation","keywords":["isaac sim","simulation","photorealistic","omniverse","robotics simulation","domain randomization"]},"sidebar":"textbook","previous":{"title":"NVIDIA Isaac Introduction","permalink":"/physical-ai/docs/module-3/nvidia-isaac-intro"},"next":{"title":"Synthetic Data Generation","permalink":"/physical-ai/docs/module-3/synthetic-data"}}');var a=r(4848),t=r(8453);const o={id:"isaac-sim",title:"Isaac Sim",sidebar_position:3,description:"Comprehensive guide to NVIDIA Isaac Sim for photorealistic robotics simulation",keywords:["isaac sim","simulation","photorealistic","omniverse","robotics simulation","domain randomization"]},s="Isaac Sim: Photorealistic Robotics Simulation",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Isaac Sim Architecture",id:"isaac-sim-architecture",level:2},{value:"Core Components",id:"core-components",level:3},{value:"USD (Universal Scene Description)",id:"usd-universal-scene-description",level:3},{value:"USD Prim Hierarchy Example",id:"usd-prim-hierarchy-example",level:4},{value:"Installation and Setup",id:"installation-and-setup",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Isaac Sim Installation",id:"isaac-sim-installation",level:3},{value:"Method 1: Direct Installation",id:"method-1-direct-installation",level:4},{value:"Method 2: Docker Installation",id:"method-2-docker-installation",level:4},{value:"Initial Configuration",id:"initial-configuration",level:3},{value:"Creating Photorealistic Environments",id:"creating-photorealistic-environments",level:2},{value:"Environment Setup Script",id:"environment-setup-script",level:3},{value:"Material and Texture Configuration",id:"material-and-texture-configuration",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Understanding Domain Randomization",id:"understanding-domain-randomization",level:3},{value:"Domain Randomization Implementation",id:"domain-randomization-implementation",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Data Generation Pipeline",id:"data-generation-pipeline",level:3},{value:"ROS/ROS 2 Integration",id:"rosros-2-integration",level:2},{value:"Isaac Sim ROS Bridge",id:"isaac-sim-ros-bridge",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"GPU Optimization Techniques",id:"gpu-optimization-techniques",level:3},{value:"Troubleshooting and Best Practices",id:"troubleshooting-and-best-practices",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Best Practices",id:"best-practices",level:3},{value:"Learning Objectives Review",id:"learning-objectives-review",level:2},{value:"Practical Exercise",id:"practical-exercise",level:2},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Further Reading",id:"further-reading",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"isaac-sim-photorealistic-robotics-simulation",children:"Isaac Sim: Photorealistic Robotics Simulation"})}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim is NVIDIA's high-fidelity simulation environment built on the Omniverse platform. It provides photorealistic rendering, accurate physics simulation, and domain randomization capabilities for training AI models for robotics applications."}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand Isaac Sim architecture and core components"}),"\n",(0,a.jsx)(e.li,{children:"Set up and configure Isaac Sim for robotics applications"}),"\n",(0,a.jsx)(e.li,{children:"Create photorealistic environments for robotics training"}),"\n",(0,a.jsx)(e.li,{children:"Implement domain randomization techniques"}),"\n",(0,a.jsx)(e.li,{children:"Generate synthetic datasets for AI model training"}),"\n",(0,a.jsx)(e.li,{children:"Integrate Isaac Sim with ROS/ROS 2 workflows"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"isaac-sim-architecture",children:"Isaac Sim Architecture"}),"\n",(0,a.jsx)(e.h3,{id:"core-components",children:"Core Components"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim consists of several integrated components:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                    Isaac Sim Architecture                   \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502  \u2502   USD Scene     \u2502  \u2502   PhysX Physics \u2502  \u2502   RTX       \u2502  \u2502\r\n\u2502  \u2502   Description   \u2502  \u2502   Engine        \u2502  \u2502   Renderer  \u2502  \u2502\r\n\u2502  \u2502                 \u2502  \u2502                 \u2502  \u2502             \u2502  \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502           \u2502                     \u2502                   \u2502       \u2502\r\n\u2502           \u25bc                     \u25bc                   \u25bc       \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\r\n\u2502  \u2502   Scene Graph   \u2502  \u2502   Collision     \u2502  \u2502   Lighting  \u2502  \u2502\r\n\u2502  \u2502   Management    \u2502  \u2502   Detection     \u2502  \u2502   System    \u2502  \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\r\n\u2502           \u2502                     \u2502                   \u2502       \u2502\r\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\r\n\u2502                                 \u25bc                           \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\r\n\u2502  \u2502              Omniverse Kit Framework                    \u2502 \u2502\r\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502\r\n\u2502  \u2502  \u2502 Extensions  \u2502  \u2502 Extensions  \u2502  \u2502 Extensions      \u2502  \u2502 \u2502\r\n\u2502  \u2502  \u2502 (Robotics)  \u2502  \u2502 (AI/ML)     \u2502  \u2502 (ROS Bridge)    \u2502  \u2502 \u2502\r\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(e.h3,{id:"usd-universal-scene-description",children:"USD (Universal Scene Description)"}),"\n",(0,a.jsx)(e.p,{children:"USD is the core scene representation format used by Isaac Sim:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Hierarchical Structure"}),": Tree-based scene organization"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Layering System"}),": Composable scene layers"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Variant Sets"}),": Multiple scene configurations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Animation Support"}),": Timeline and keyframe animation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Multi-User Collaboration"}),": Concurrent editing capabilities"]}),"\n"]}),"\n",(0,a.jsx)(e.h4,{id:"usd-prim-hierarchy-example",children:"USD Prim Hierarchy Example"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# Isaac Sim USD prim structure\r\n/World\r\n\u251c\u2500\u2500 /GroundPlane\r\n\u251c\u2500\u2500 /Lights\r\n\u2502   \u251c\u2500\u2500 /DomeLight\r\n\u2502   \u251c\u2500\u2500 /KeyLight\r\n\u2502   \u2514\u2500\u2500 /FillLight\r\n\u251c\u2500\u2500 /Cameras\r\n\u2502   \u2514\u2500\u2500 /RGB_Camera\r\n\u251c\u2500\u2500 /Robots\r\n\u2502   \u2514\u2500\u2500 /MyRobot\r\n\u2502       \u251c\u2500\u2500 /base_link\r\n\u2502       \u251c\u2500\u2500 /left_wheel\r\n\u2502       \u2514\u2500\u2500 /right_wheel\r\n\u2514\u2500\u2500 /Objects\r\n    \u251c\u2500\u2500 /Table\r\n    \u2514\u2500\u2500 /Cubes\r\n        \u251c\u2500\u2500 /Cube_1\r\n        \u2514\u2500\u2500 /Cube_2\n"})}),"\n",(0,a.jsx)(e.h2,{id:"installation-and-setup",children:"Installation and Setup"}),"\n",(0,a.jsx)(e.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(e.p,{children:"Before installing Isaac Sim, ensure your system meets the requirements:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Check GPU compatibility\r\nnvidia-smi\r\n\r\n# Verify CUDA installation\r\nnvcc --version\r\n\r\n# Check available disk space (recommended: 100GB+)\r\ndf -h $HOME\r\n\r\n# Install dependencies\r\nsudo apt update\r\nsudo apt install -y build-essential cmake git python3-dev python3-pip\n"})}),"\n",(0,a.jsx)(e.h3,{id:"isaac-sim-installation",children:"Isaac Sim Installation"}),"\n",(0,a.jsx)(e.h4,{id:"method-1-direct-installation",children:"Method 1: Direct Installation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Download Isaac Sim\r\nwget https://developer.nvidia.com/isaac/downloads/isaac-sim-2023-2-0-release.tar.gz\r\n\r\n# Extract\r\ntar -xzf isaac-sim-2023-2-0-release.tar.gz\r\n\r\n# Navigate to directory\r\ncd isaac-sim-2023.2.0\r\n\r\n# Install\r\n./install.sh\r\n\r\n# Launch Isaac Sim\r\n./isaac-sim.sh\n"})}),"\n",(0,a.jsx)(e.h4,{id:"method-2-docker-installation",children:"Method 2: Docker Installation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:'# Pull Isaac Sim Docker image\r\ndocker pull nvcr.io/nvidia/isaac-sim:2023.2.1\r\n\r\n# Run Isaac Sim container\r\ndocker run --gpus all -it \\\r\n  --rm \\\r\n  --network=host \\\r\n  --volume=/tmp/.X11-unix:/tmp/.X11-unix:rw \\\r\n  --volume=$HOME/.Xauthority:/root/.Xauthority:rw \\\r\n  --volume=$PWD:/workspace \\\r\n  --env="DISPLAY" \\\r\n  --env="ACCEPT_EULA=Y" \\\r\n  --env="NVIDIA_VISIBLE_DEVICES=all" \\\r\n  --env="NVIDIA_DRIVER_CAPABILITIES=all" \\\r\n  --name="isaac-sim" \\\r\n  nvcr.io/nvidia/isaac-sim:2023.2.1\n'})}),"\n",(0,a.jsx)(e.h3,{id:"initial-configuration",children:"Initial Configuration"}),"\n",(0,a.jsx)(e.p,{children:"After installation, configure Isaac Sim for optimal performance:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Configure Isaac Sim settings programmatically\r\nimport omni\r\nfrom omni.isaac.core.utils.settings import set_carb_setting\r\n\r\n# Set rendering quality\r\nset_carb_setting("/app/viewport/renderQuality", 3)  # High quality\r\n\r\n# Set physics substeps for stability\r\nset_carb_setting("/physics/solverVelocityIterationCount", 8)\r\nset_carb_setting("/physics/solverPositionIterationCount", 4)\r\n\r\n# Configure texture streaming\r\nset_carb_setting("/renderer/textureStreaming/resolutionScale", 1.0)\r\nset_carb_setting("/renderer/textureStreaming/enable", True)\r\n\r\n# Set up GPU acceleration\r\nset_carb_setting("/renderer/antiAliasingMode", 1)  # FXAA\r\nset_carb_setting("/renderer/physicallyBased", True)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"creating-photorealistic-environments",children:"Creating Photorealistic Environments"}),"\n",(0,a.jsx)(e.h3,{id:"environment-setup-script",children:"Environment Setup Script"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import omni\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.core.utils.prims import get_prim_at_path\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.carb import carb_settings_path\r\nimport carb\r\n\r\ndef setup_photorealistic_environment():\r\n    """Create a photorealistic environment for robotics simulation"""\r\n\r\n    # Initialize the world\r\n    world = World(stage_units_in_meters=1.0)\r\n\r\n    # Add ground plane\r\n    world.scene.add_default_ground_plane(\r\n        prim_path="/World/defaultGroundPlane",\r\n        name="default_ground_plane",\r\n        static_friction=0.5,\r\n        dynamic_friction=0.5,\r\n        restitution=0.8\r\n    )\r\n\r\n    # Add dome light for realistic environment lighting\r\n    dome_light = world.scene.add(\r\n        omni.isaac.core.objects.DomeLight(\r\n            prim_path="/World/DomeLight",\r\n            name="dome_light",\r\n            intensity=3000,\r\n            color=(0.8, 0.8, 0.8)\r\n        )\r\n    )\r\n\r\n    # Add key light for directional illumination\r\n    key_light = world.scene.add(\r\n        omni.isaac.core.objects.DistantLight(\r\n            prim_path="/World/KeyLight",\r\n            name="key_light",\r\n            intensity=400,\r\n            color=(1.0, 1.0, 1.0),\r\n            position=(5, 5, 10),\r\n            look_at=(0, 0, 0)\r\n        )\r\n    )\r\n\r\n    # Add fill light to reduce harsh shadows\r\n    fill_light = world.scene.add(\r\n        omni.isaac.core.objects.DistantLight(\r\n            prim_path="/World/FillLight",\r\n            name="fill_light",\r\n            intensity=150,\r\n            color=(0.7, 0.7, 0.9),\r\n            position=(-3, 2, 8),\r\n            look_at=(0, 0, 0)\r\n        )\r\n    )\r\n\r\n    return world\r\n\r\ndef add_textured_objects(world):\r\n    """Add textured objects to the environment"""\r\n\r\n    # Add a textured table\r\n    table = world.scene.add(\r\n        omni.isaac.core.objects.FixedCuboid(\r\n            prim_path="/World/Table",\r\n            name="table",\r\n            position=[0, 0, 0.5],\r\n            size=[1.0, 0.6, 0.05],\r\n            color=[0.8, 0.6, 0.4]\r\n        )\r\n    )\r\n\r\n    # Add textured cubes with random materials\r\n    materials = [\r\n        (0.8, 0.2, 0.2),  # Red\r\n        (0.2, 0.8, 0.2),  # Green\r\n        (0.2, 0.2, 0.8),  # Blue\r\n        (0.8, 0.8, 0.2),  # Yellow\r\n    ]\r\n\r\n    import random\r\n    for i in range(4):\r\n        cube = world.scene.add(\r\n            omni.isaac.core.objects.DynamicCuboid(\r\n                prim_path=f"/World/Cube_{i}",\r\n                name=f"cube_{i}",\r\n                position=[random.uniform(-0.4, 0.4), random.uniform(-0.3, 0.3), 0.55],\r\n                size=0.1,\r\n                color=materials[i]\r\n            )\r\n        )\r\n\r\ndef main():\r\n    world = setup_photorealistic_environment()\r\n    add_textured_objects(world)\r\n\r\n    # Play the simulation\r\n    world.reset()\r\n\r\n    # Run simulation loop\r\n    for i in range(1000):\r\n        world.step(render=True)\r\n\r\n    world.stop()\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,a.jsx)(e.h3,{id:"material-and-texture-configuration",children:"Material and Texture Configuration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import omni\r\nfrom pxr import UsdShade, Sdf, Gf, UsdGeom\r\n\r\ndef create_realistic_materials():\r\n    """Create realistic materials for photorealistic rendering"""\r\n\r\n    stage = omni.usd.get_context().get_stage()\r\n\r\n    # Create a realistic metal material\r\n    metal_material_path = Sdf.Path("/World/Materials/MetalMaterial")\r\n    metal_material = UsdShade.Material.Define(stage, metal_material_path)\r\n\r\n    # Create PBR shader\r\n    metal_shader = UsdShade.Shader.Define(stage, metal_material_path.AppendChild("Surface"))\r\n    metal_shader.CreateIdAttr("OmniPBR")\r\n\r\n    # Set material properties\r\n    metal_shader.CreateInput("diffuse_color", Sdf.ValueTypeNames.Color3f).Set(Gf.Vec3f(0.7, 0.7, 0.8))\r\n    metal_shader.CreateInput("metallic", Sdf.ValueTypeNames.Float).Set(0.9)\r\n    metal_shader.CreateInput("roughness", Sdf.ValueTypeNames.Float).Set(0.1)\r\n    metal_shader.CreateInput("specular_reflection", Sdf.ValueTypeNames.Float).Set(0.5)\r\n\r\n    # Connect shader to material\r\n    metal_material.CreateSurfaceOutput().ConnectToSource(metal_shader.ConnectableAPI(), "outputs:surface")\r\n\r\n    # Create a realistic fabric material\r\n    fabric_material_path = Sdf.Path("/World/Materials/FabricMaterial")\r\n    fabric_material = UsdShade.Material.Define(stage, fabric_material_path)\r\n\r\n    fabric_shader = UsdShade.Shader.Define(stage, fabric_material_path.AppendChild("Surface"))\r\n    fabric_shader.CreateIdAttr("OmniPBR")\r\n\r\n    fabric_shader.CreateInput("diffuse_color", Sdf.ValueTypeNames.Color3f).Set(Gf.Vec3f(0.4, 0.6, 0.8))\r\n    fabric_shader.CreateInput("metallic", Sdf.ValueTypeNames.Float).Set(0.0)\r\n    fabric_shader.CreateInput("roughness", Sdf.ValueTypeNames.Float).Set(0.7)\r\n    fabric_shader.CreateInput("specular_reflection", Sdf.ValueTypeNames.Float).Set(0.2)\r\n\r\n    fabric_material.CreateSurfaceOutput().ConnectToSource(fabric_shader.ConnectableAPI(), "outputs:surface")\r\n\r\ndef apply_material_to_object(object_path, material_path):\r\n    """Apply material to an object"""\r\n    stage = omni.usd.get_context().get_stage()\r\n    prim = stage.GetPrimAtPath(object_path)\r\n\r\n    # Apply material to the object\r\n    UsdShade.MaterialBindingAPI(prim).Bind(\r\n        UsdShade.Material(stage.GetPrimAtPath(material_path))\r\n    )\n'})}),"\n",(0,a.jsx)(e.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,a.jsx)(e.h3,{id:"understanding-domain-randomization",children:"Understanding Domain Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Domain randomization is a technique that increases the diversity of training data by varying environmental properties randomly during simulation:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Lighting Conditions"}),": Randomize light positions, intensities, and colors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Material Properties"}),": Randomize colors, textures, and surface properties"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Object Placement"}),": Randomize positions, orientations, and scales"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Camera Parameters"}),": Randomize focal length, sensor size, and noise"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Background Environments"}),": Randomize backgrounds and environments"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"domain-randomization-implementation",children:"Domain Randomization Implementation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import omni\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.utils.prims import get_prim_at_path\r\nimport numpy as np\r\nimport random\r\n\r\nclass DomainRandomizer:\r\n    def __init__(self):\r\n        self.world = None\r\n        self.randomization_config = {}\r\n        self.step_count = 0\r\n\r\n    def setup_randomization(self, config):\r\n        \"\"\"Configure domain randomization parameters\"\"\"\r\n        self.randomization_config = config\r\n\r\n    def randomize_lighting(self):\r\n        \"\"\"Randomize lighting conditions\"\"\"\r\n        if 'lights' not in self.randomization_config:\r\n            return\r\n\r\n        lights_config = self.randomization_config['lights']\r\n\r\n        # Randomize dome light\r\n        dome_light = get_prim_at_path(\"/World/DomeLight\")\r\n        if dome_light:\r\n            # Randomize intensity\r\n            intensity = random.uniform(\r\n                lights_config['intensity']['min'],\r\n                lights_config['intensity']['max']\r\n            )\r\n            dome_light.GetAttribute(\"inputs:intensity\").Set(intensity)\r\n\r\n            # Randomize color\r\n            color = (\r\n                random.uniform(lights_config['color']['min'][0], lights_config['color']['max'][0]),\r\n                random.uniform(lights_config['color']['min'][1], lights_config['color']['max'][1]),\r\n                random.uniform(lights_config['color']['min'][2], lights_config['color']['max'][2])\r\n            )\r\n            dome_light.GetAttribute(\"inputs:color\").Set(color)\r\n\r\n    def randomize_materials(self):\r\n        \"\"\"Randomize material properties\"\"\"\r\n        if 'materials' not in self.randomization_config:\r\n            return\r\n\r\n        materials_config = self.randomization_config['materials']\r\n\r\n        # Iterate through objects and randomize materials\r\n        stage = omni.usd.get_context().get_stage()\r\n        for prim in stage.Traverse():\r\n            if prim.GetTypeName() == \"Geometry\":\r\n                # Randomize diffuse color\r\n                if random.random() < materials_config['color_variation_probability']:\r\n                    new_color = (\r\n                        random.uniform(0.1, 1.0),\r\n                        random.uniform(0.1, 1.0),\r\n                        random.uniform(0.1, 1.0)\r\n                    )\r\n\r\n                    # Find material shader and update color\r\n                    material_binding_api = omni.usd.get_prim_material(prim)\r\n                    if material_binding_api:\r\n                        shader = material_binding_api.GetBoundMaterial()\r\n                        if shader:\r\n                            shader.GetShader().GetInput(\"diffuse_color\").Set(new_color)\r\n\r\n    def randomize_objects(self):\r\n        \"\"\"Randomize object positions and properties\"\"\"\r\n        if 'objects' not in self.randomization_config:\r\n            return\r\n\r\n        objects_config = self.randomization_config['objects']\r\n\r\n        # Randomize object positions\r\n        for i in range(objects_config['count']):\r\n            object_path = f\"/World/Object_{i}\"\r\n            prim = get_prim_at_path(object_path)\r\n\r\n            if prim:\r\n                # Randomize position\r\n                new_pos = [\r\n                    random.uniform(objects_config['position']['x']['min'], objects_config['position']['x']['max']),\r\n                    random.uniform(objects_config['position']['y']['min'], objects_config['position']['y']['max']),\r\n                    random.uniform(objects_config['position']['z']['min'], objects_config['position']['z']['max'])\r\n                ]\r\n\r\n                # Apply new position\r\n                xform = UsdGeom.Xformable(prim)\r\n                xform.AddTranslateOp().Set(new_pos)\r\n\r\n    def randomize_cameras(self):\r\n        \"\"\"Randomize camera parameters\"\"\"\r\n        if 'cameras' not in self.randomization_config:\r\n            return\r\n\r\n        cameras_config = self.randomization_config['cameras']\r\n\r\n        # Randomize camera intrinsics\r\n        camera_prim = get_prim_at_path(\"/World/Camera\")\r\n        if camera_prim:\r\n            # Randomize focal length\r\n            focal_length = random.uniform(\r\n                cameras_config['focal_length']['min'],\r\n                cameras_config['focal_length']['max']\r\n            )\r\n            camera_prim.GetAttribute(\"inputs:horizontalAperture\").Set(focal_length)\r\n\r\n    def apply_randomization(self):\r\n        \"\"\"Apply all randomization effects\"\"\"\r\n        self.randomize_lighting()\r\n        self.randomize_materials()\r\n        self.randomize_objects()\r\n        self.randomize_cameras()\r\n\r\n        self.step_count += 1\r\n\r\n        # Reset after certain steps if needed\r\n        if self.step_count % self.randomization_config.get('reset_interval', 100) == 0:\r\n            self.reset_randomization()\r\n\r\n    def reset_randomization(self):\r\n        \"\"\"Reset randomization for new episode\"\"\"\r\n        self.step_count = 0\r\n        # Optionally reset specific parameters\r\n\r\ndef setup_domain_randomization():\r\n    \"\"\"Setup domain randomization configuration\"\"\"\r\n\r\n    config = {\r\n        'lights': {\r\n            'intensity': {'min': 1000, 'max': 5000},\r\n            'color': {\r\n                'min': [0.5, 0.5, 0.5],\r\n                'max': [1.0, 1.0, 1.0]\r\n            }\r\n        },\r\n        'materials': {\r\n            'color_variation_probability': 0.3\r\n        },\r\n        'objects': {\r\n            'count': 10,\r\n            'position': {\r\n                'x': {'min': -2.0, 'max': 2.0},\r\n                'y': {'min': -2.0, 'max': 2.0},\r\n                'z': {'min': 0.1, 'max': 2.0}\r\n            }\r\n        },\r\n        'cameras': {\r\n            'focal_length': {'min': 18.0, 'max': 55.0}\r\n        },\r\n        'reset_interval': 50\r\n    }\r\n\r\n    randomizer = DomainRandomizer()\r\n    randomizer.setup_randomization(config)\r\n\r\n    return randomizer\r\n\r\n# Example usage\r\ndef main():\r\n    # Setup world\r\n    world = World(stage_units_in_meters=1.0)\r\n\r\n    # Setup domain randomization\r\n    randomizer = setup_domain_randomization()\r\n\r\n    # Play simulation\r\n    world.play()\r\n\r\n    # Run simulation with randomization\r\n    for i in range(10000):\r\n        if i % 10 == 0:  # Apply randomization every 10 steps\r\n            randomizer.apply_randomization()\r\n\r\n        world.step(render=True)\r\n\r\n    world.stop()\r\n\r\nif __name__ == \"__main__\":\r\n    main()\n"})}),"\n",(0,a.jsx)(e.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,a.jsx)(e.h3,{id:"data-generation-pipeline",children:"Data Generation Pipeline"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import omni\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.sensor import Camera\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport json\r\nimport os\r\nfrom pxr import UsdGeom\r\n\r\nclass SyntheticDataGenerator:\r\n    def __init__(self, output_dir="synthetic_data"):\r\n        self.output_dir = output_dir\r\n        self.world = None\r\n        self.cameras = []\r\n        self.annotation_data = []\r\n\r\n        # Create output directory\r\n        os.makedirs(output_dir, exist_ok=True)\r\n        os.makedirs(os.path.join(output_dir, "images"), exist_ok=True)\r\n        os.makedirs(os.path.join(output_dir, "annotations"), exist_ok=True)\r\n\r\n    def add_camera(self, name, position, look_at, resolution=(640, 480)):\r\n        """Add a camera for data capture"""\r\n        camera = Camera(\r\n            prim_path=f"/World/Cameras/{name}",\r\n            name=name,\r\n            position=position,\r\n            look_at=look_at,\r\n            resolution=resolution\r\n        )\r\n\r\n        self.cameras.append({\r\n            \'camera\': camera,\r\n            \'name\': name,\r\n            \'resolution\': resolution\r\n        })\r\n\r\n        return camera\r\n\r\n    def capture_rgb_data(self, camera_idx=0):\r\n        """Capture RGB image from camera"""\r\n        camera = self.cameras[camera_idx][\'camera\']\r\n\r\n        # Get RGB data\r\n        rgb_data = camera.get_rgb()\r\n\r\n        # Convert to PIL Image\r\n        img = Image.fromarray(rgb_data, mode="RGB")\r\n\r\n        return img\r\n\r\n    def capture_depth_data(self, camera_idx=0):\r\n        """Capture depth data from camera"""\r\n        camera = self.cameras[camera_idx][\'camera\']\r\n\r\n        # Get depth data\r\n        depth_data = camera.get_depth()\r\n\r\n        return depth_data\r\n\r\n    def capture_segmentation_data(self, camera_idx=0):\r\n        """Capture semantic segmentation data"""\r\n        camera = self.cameras[camera_idx][\'camera\']\r\n\r\n        # Get segmentation data\r\n        seg_data = camera.get_semantic_segmentation()\r\n\r\n        return seg_data\r\n\r\n    def generate_annotations(self):\r\n        """Generate annotation data for the current scene"""\r\n        stage = omni.usd.get_context().get_stage()\r\n\r\n        annotations = {\r\n            \'objects\': [],\r\n            \'scene\': {\r\n                \'timestamp\': self.world.current_time_step_index,\r\n                \'environment\': \'photorealistic_room\'\r\n            }\r\n        }\r\n\r\n        # Extract object information\r\n        for prim in stage.Traverse():\r\n            if prim.GetTypeName() in ["Mesh", "Cone", "Cube", "Cylinder", "Sphere"]:\r\n                prim_name = prim.GetName()\r\n\r\n                # Get object pose\r\n                xformable = UsdGeom.Xformable(prim)\r\n                transform_matrix = xformable.ComputeLocalToWorldTransform(0)\r\n\r\n                # Get bounding box\r\n                bbox_cache = UsdGeom.BBoxCache(0, [UsdGeom.Tokens.default_])\r\n                bbox = bbox_cache.ComputeWorldBound(prim)\r\n\r\n                if not bbox.IsEmpty():\r\n                    min_point = bbox.GetMin()\r\n                    max_point = bbox.GetMax()\r\n\r\n                    annotations[\'objects\'].append({\r\n                        \'name\': prim_name,\r\n                        \'type\': prim.GetTypeName(),\r\n                        \'bbox\': {\r\n                            \'min\': [min_point[0], min_point[1], min_point[2]],\r\n                            \'max\': [max_point[0], max_point[1], max_point[2]]\r\n                        },\r\n                        \'pose\': {\r\n                            \'translation\': [transform_matrix[i][3] for i in range(3)],\r\n                            \'rotation_matrix\': [[transform_matrix[i][j] for j in range(3)] for i in range(3)]\r\n                        }\r\n                    })\r\n\r\n        return annotations\r\n\r\n    def save_data_sample(self, sample_id):\r\n        """Save a complete data sample with all modalities"""\r\n        # Create sample directory\r\n        sample_dir = os.path.join(self.output_dir, f"sample_{sample_id}")\r\n        os.makedirs(sample_dir, exist_ok=True)\r\n\r\n        # Capture data from all cameras\r\n        for cam_idx, cam_info in enumerate(self.cameras):\r\n            # RGB image\r\n            rgb_img = self.capture_rgb_data(cam_idx)\r\n            rgb_path = os.path.join(sample_dir, f"{cam_info[\'name\']}_rgb.png")\r\n            rgb_img.save(rgb_path)\r\n\r\n            # Depth data\r\n            depth_data = self.capture_depth_data(cam_idx)\r\n            depth_path = os.path.join(sample_dir, f"{cam_info[\'name\']}_depth.npy")\r\n            np.save(depth_path, depth_data)\r\n\r\n            # Segmentation data\r\n            seg_data = self.capture_segmentation_data(cam_idx)\r\n            seg_path = os.path.join(sample_dir, f"{cam_info[\'name\']}_seg.png")\r\n            seg_img = Image.fromarray(seg_data.astype(np.uint8), mode="L")\r\n            seg_img.save(seg_path)\r\n\r\n        # Generate and save annotations\r\n        annotations = self.generate_annotations()\r\n        annotation_path = os.path.join(sample_dir, "annotations.json")\r\n        with open(annotation_path, \'w\') as f:\r\n            json.dump(annotations, f, indent=2)\r\n\r\n        # Add to annotation data\r\n        self.annotation_data.append({\r\n            \'sample_id\': sample_id,\r\n            \'path\': sample_dir,\r\n            \'annotations\': annotations\r\n        })\r\n\r\n    def generate_dataset(self, num_samples=1000):\r\n        """Generate a complete synthetic dataset"""\r\n        print(f"Generating {num_samples} synthetic data samples...")\r\n\r\n        for i in range(num_samples):\r\n            if i % 100 == 0:\r\n                print(f"Generated {i}/{num_samples} samples")\r\n\r\n            # Apply domain randomization\r\n            # (Assuming domain randomizer is set up)\r\n\r\n            # Save the current sample\r\n            self.save_data_sample(i)\r\n\r\n            # Step the simulation\r\n            self.world.step(render=True)\r\n\r\n        # Save dataset metadata\r\n        metadata = {\r\n            \'total_samples\': num_samples,\r\n            \'generated_at\': str(self.world.current_time_step_index),\r\n            \'cameras_used\': [cam[\'name\'] for cam in self.cameras],\r\n            \'annotations_format\': \'json\',\r\n            \'modalities\': [\'rgb\', \'depth\', \'segmentation\']\r\n        }\r\n\r\n        metadata_path = os.path.join(self.output_dir, "metadata.json")\r\n        with open(metadata_path, \'w\') as f:\r\n            json.dump(metadata, f, indent=2)\r\n\r\n        print(f"Dataset generation complete! Saved to {self.output_dir}")\r\n\r\ndef setup_synthetic_data_pipeline():\r\n    """Setup the complete synthetic data generation pipeline"""\r\n\r\n    # Initialize world\r\n    world = World(stage_units_in_meters=1.0)\r\n\r\n    # Setup environment\r\n    world.scene.add_default_ground_plane()\r\n\r\n    # Add lighting\r\n    world.scene.add(\r\n        omni.isaac.core.objects.DomeLight(\r\n            prim_path="/World/DomeLight",\r\n            name="dome_light",\r\n            intensity=3000\r\n        )\r\n    )\r\n\r\n    # Add cameras for data capture\r\n    generator = SyntheticDataGenerator()\r\n    generator.world = world\r\n\r\n    # Add multiple cameras for different viewpoints\r\n    generator.add_camera(\r\n        name="front_camera",\r\n        position=[2, 0, 1],\r\n        look_at=[0, 0, 0.5],\r\n        resolution=(640, 480)\r\n    )\r\n\r\n    generator.add_camera(\r\n        name="top_camera",\r\n        position=[0, 0, 3],\r\n        look_at=[0, 0, 0],\r\n        resolution=(640, 480)\r\n    )\r\n\r\n    return world, generator\r\n\r\n# Example usage\r\ndef main():\r\n    world, generator = setup_synthetic_data_pipeline()\r\n\r\n    # Play the simulation\r\n    world.play()\r\n\r\n    # Generate dataset\r\n    generator.generate_dataset(num_samples=100)  # Reduced for example\r\n\r\n    # Stop simulation\r\n    world.stop()\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,a.jsx)(e.h2,{id:"rosros-2-integration",children:"ROS/ROS 2 Integration"}),"\n",(0,a.jsx)(e.h3,{id:"isaac-sim-ros-bridge",children:"Isaac Sim ROS Bridge"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import omni\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.utils.extensions import enable_extension\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nimport carb\r\n\r\ndef setup_ros_bridge():\r\n    """Setup ROS bridge for Isaac Sim"""\r\n\r\n    # Enable ROS bridge extension\r\n    enable_extension("omni.isaac.ros2_bridge")\r\n\r\n    # Initialize world with ROS support\r\n    world = World(stage_units_in_meters=1.0)\r\n\r\n    # Add robot to simulation\r\n    add_reference_to_stage(\r\n        usd_path="path/to/robot/model.usd",\r\n        prim_path="/World/Robot"\r\n    )\r\n\r\n    # Configure ROS settings\r\n    settings = carb.settings.get_settings()\r\n    settings.set("/app/ros2_context", "isaac_sim")\r\n    settings.set("/app/ros2_namespace", "isaac_sim_robot")\r\n\r\n    return world\r\n\r\ndef ros_integration_example():\r\n    """Example of ROS integration with Isaac Sim"""\r\n\r\n    world = setup_ros_bridge()\r\n\r\n    # Import ROS bridge components\r\n    try:\r\n        import rclpy\r\n        from geometry_msgs.msg import Twist\r\n        from sensor_msgs.msg import Image, CameraInfo\r\n        from std_msgs.msg import String\r\n\r\n        # Initialize ROS\r\n        rclpy.init()\r\n\r\n        # Create ROS node\r\n        ros_node = rclpy.create_node(\'isaac_sim_controller\')\r\n\r\n        # Publishers for robot control\r\n        cmd_vel_pub = ros_node.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        status_pub = ros_node.create_publisher(String, \'/status\', 10)\r\n\r\n        # Subscribers for sensor data\r\n        def image_callback(msg):\r\n            # Process camera image from Isaac Sim\r\n            pass\r\n\r\n        image_sub = ros_node.create_subscription(\r\n            Image, \'/camera/image_raw\', image_callback, 10\r\n        )\r\n\r\n        # Timer for sending commands\r\n        def send_commands():\r\n            twist_msg = Twist()\r\n            twist_msg.linear.x = 0.5  # Move forward\r\n            twist_msg.angular.z = 0.1  # Turn slightly\r\n            cmd_vel_pub.publish(twist_msg)\r\n\r\n        # Create timer to send commands every 100ms\r\n        timer = ros_node.create_timer(0.1, send_commands)\r\n\r\n        # Main simulation loop\r\n        world.reset()\r\n\r\n        try:\r\n            while simulation_app.is_running():\r\n                # Process ROS callbacks\r\n                rclpy.spin_once(ros_node, timeout_sec=0.01)\r\n\r\n                # Step simulation\r\n                world.step(render=True)\r\n\r\n                # Publish status\r\n                status_msg = String()\r\n                status_msg.data = f"Simulation step: {world.current_time_step_index}"\r\n                status_pub.publish(status_msg)\r\n\r\n        except KeyboardInterrupt:\r\n            print("Stopping simulation...")\r\n        finally:\r\n            # Cleanup\r\n            ros_node.destroy_timer(timer)\r\n            ros_node.destroy_node()\r\n            rclpy.shutdown()\r\n\r\n    except ImportError:\r\n        print("ROS2 not available, skipping ROS integration")\r\n\r\ndef main():\r\n    # Setup and run ROS integration example\r\n    ros_integration_example()\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,a.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,a.jsx)(e.h3,{id:"gpu-optimization-techniques",children:"GPU Optimization Techniques"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import omni\r\nfrom omni.isaac.core.utils.settings import set_carb_setting\r\n\r\ndef optimize_isaac_sim_performance():\r\n    """Optimize Isaac Sim for maximum performance"""\r\n\r\n    # Set rendering quality appropriately\r\n    set_carb_setting("/app/viewport/renderQuality", 1)  # Medium quality for better performance\r\n\r\n    # Optimize physics solver\r\n    set_carb_setting("/physics/solverVelocityIterationCount", 4)  # Reduce iterations\r\n    set_carb_setting("/physics/solverPositionIterationCount", 2)  # Reduce iterations\r\n    set_carb_setting("/physics/maxSubSteps", 1)  # Single substep for performance\r\n\r\n    # Optimize rendering\r\n    set_carb_setting("/renderer/antiAliasingMode", 0)  # Disable anti-aliasing\r\n    set_carb_setting("/renderer/lightCulling", True)  # Enable light culling\r\n    set_carb_setting("/renderer/clusteredLighting", True)  # Enable clustered lighting\r\n\r\n    # Optimize texture streaming\r\n    set_carb_setting("/renderer/textureStreaming/resolutionScale", 0.5)  # Lower resolution\r\n    set_carb_setting("/renderer/textureStreaming/maxTexturePoolSize", 1024)  # Limit pool size\r\n\r\n    # Optimize shadow maps\r\n    set_carb_setting("/renderer/shadowMap/atmosphericLight", [2048, 2048])  # Smaller shadow maps\r\n    set_carb_setting("/renderer/shadowMap/distantLight", [1024, 1024])\r\n\r\n    # Disable unnecessary features\r\n    set_carb_setting("/app/enableProgressiveRenderer", False)  # Disable progressive rendering\r\n    set_carb_setting("/app/renderer/enableViewportRender", False)  # Render off-screen if not needed\r\n\r\ndef configure_simulation_for_training():\r\n    """Configure simulation for maximum training efficiency"""\r\n\r\n    # Optimize for synthetic data generation\r\n    set_carb_setting("/app/viewport/displayOptions", 0)  # Hide viewport for headless training\r\n    set_carb_setting("/app/window/visible", False)  # Hide window\r\n\r\n    # Optimize for domain randomization\r\n    set_carb_setting("/app/autoSave/enabled", False)  # Disable auto-save during training\r\n    set_carb_setting("/app/backup/enabled", False)  # Disable backup during training\r\n\r\n    # Optimize for high-frequency simulation\r\n    set_carb_setting("/app/runInBackground", True)  # Allow background execution\r\n    set_carb_setting("/app/enableIdleRun", False)  # Disable idle processing\r\n\r\ndef setup_optimized_world():\r\n    """Setup world with performance optimizations"""\r\n\r\n    # Apply optimizations\r\n    optimize_isaac_sim_performance()\r\n    configure_simulation_for_training()\r\n\r\n    # Initialize world with optimized settings\r\n    from omni.isaac.core import World\r\n    world = World(\r\n        stage_units_in_meters=1.0,\r\n        physics_dt=1.0/60.0,  # 60 FPS physics\r\n        rendering_dt=1.0/30.0  # 30 FPS rendering (can be adjusted)\r\n    )\r\n\r\n    return world\n'})}),"\n",(0,a.jsx)(e.h2,{id:"troubleshooting-and-best-practices",children:"Troubleshooting and Best Practices"}),"\n",(0,a.jsx)(e.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"GPU Memory Issues"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Reduce scene complexity"}),"\n",(0,a.jsx)(e.li,{children:"Lower texture resolution"}),"\n",(0,a.jsx)(e.li,{children:"Use texture streaming"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Performance Bottlenecks"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Profile with NVIDIA Nsight"}),"\n",(0,a.jsx)(e.li,{children:"Optimize USD stage complexity"}),"\n",(0,a.jsx)(e.li,{children:"Use instancing for repeated objects"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Physics Instability"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Reduce physics timestep"}),"\n",(0,a.jsx)(e.li,{children:"Adjust solver iterations"}),"\n",(0,a.jsx)(e.li,{children:"Verify mass and inertia properties"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Stage Organization"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Use meaningful prim paths"}),"\n",(0,a.jsx)(e.li,{children:"Organize objects hierarchically"}),"\n",(0,a.jsx)(e.li,{children:"Use variants for different configurations"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Asset Management"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Use USD composition for complex scenes"}),"\n",(0,a.jsx)(e.li,{children:"Reference external assets instead of copying"}),"\n",(0,a.jsx)(e.li,{children:"Use point instancers for repeated objects"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Simulation Efficiency"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Batch randomization operations"}),"\n",(0,a.jsx)(e.li,{children:"Use async operations when possible"}),"\n",(0,a.jsx)(e.li,{children:"Cache computed values"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives-review",children:"Learning Objectives Review"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand Isaac Sim architecture and core components \u2713"}),"\n",(0,a.jsx)(e.li,{children:"Set up and configure Isaac Sim for robotics applications \u2713"}),"\n",(0,a.jsx)(e.li,{children:"Create photorealistic environments for robotics training \u2713"}),"\n",(0,a.jsx)(e.li,{children:"Implement domain randomization techniques \u2713"}),"\n",(0,a.jsx)(e.li,{children:"Generate synthetic datasets for AI model training \u2713"}),"\n",(0,a.jsx)(e.li,{children:"Integrate Isaac Sim with ROS/ROS 2 workflows \u2713"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"practical-exercise",children:"Practical Exercise"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Install Isaac Sim and verify the installation"}),"\n",(0,a.jsx)(e.li,{children:"Create a simple scene with a robot and objects"}),"\n",(0,a.jsx)(e.li,{children:"Configure domain randomization for lighting and materials"}),"\n",(0,a.jsx)(e.li,{children:"Set up synthetic data generation pipeline"}),"\n",(0,a.jsx)(e.li,{children:"Integrate with ROS for robot control"}),"\n",(0,a.jsx)(e.li,{children:"Optimize the simulation for performance"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Explain the USD scene description format and its importance in Isaac Sim."}),"\n",(0,a.jsx)(e.li,{children:"How does domain randomization improve the robustness of AI models?"}),"\n",(0,a.jsx)(e.li,{children:"What are the key components of the Isaac Sim architecture?"}),"\n",(0,a.jsx)(e.li,{children:"How do you optimize Isaac Sim for synthetic data generation?"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Isaac Sim User Guide: ",(0,a.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"https://docs.omniverse.nvidia.com/isaacsim/latest/"})]}),"\n",(0,a.jsxs)(e.li,{children:["USD Documentation: ",(0,a.jsx)(e.a,{href:"https://graphics.pixar.com/usd/docs/index.html",children:"https://graphics.pixar.com/usd/docs/index.html"})]}),"\n",(0,a.jsxs)(e.li,{children:["Omniverse Kit Documentation: ",(0,a.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/dev-guide/latest/",children:"https://docs.omniverse.nvidia.com/dev-guide/latest/"})]}),"\n",(0,a.jsx)(e.li,{children:'Domain Randomization: "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World"'}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(e.p,{children:["Continue to ",(0,a.jsx)(e.a,{href:"/physical-ai/docs/module-3/synthetic-data",children:"Synthetic Data Generation"})," to learn about creating training datasets for AI models."]})]})}function c(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(m,{...n})}):m(n)}}}]);